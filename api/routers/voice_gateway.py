"""
API - è¯­éŸ³æœåŠ¡ç½‘å…³ (å®Œæ•´ç‰ˆ)
åŒ…å«æ‰€æœ‰åŠŸèƒ½ï¼šè½¬å†™ã€ä¼šè®®çºªè¦ã€Difyé›†æˆã€OpenAIå…¼å®¹ç­‰
"""

import os
import uuid
import logging
import threading
import json
import asyncio
import zipfile
import io
import base64
from datetime import datetime
from typing import Optional, List, Union
from concurrent.futures import ThreadPoolExecutor, wait
import jieba
import jieba.analyse

from fastapi import APIRouter, UploadFile, File, Form, HTTPException, Request, WebSocket, WebSocketDisconnect
from fastapi.responses import JSONResponse, FileResponse, StreamingResponse
from werkzeug.utils import secure_filename
from docx import Document
from docx.shared import Inches, Pt, RGBColor
from docx.enum.text import WD_ALIGN_PARAGRAPH
from docx.oxml.ns import qn
from openai import OpenAI

from application.voice.pipeline_service_funasr import PipelineService  # ä½¿ç”¨FunASRç‰ˆæœ¬
from infra.audio_io.storage import AudioStorage
from infra.websocket import ws_manager
from config import FILE_CONFIG, LANGUAGE_CONFIG

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/voice", tags=["voice"])

# å…¨å±€å˜é‡
pipeline_service: Optional[PipelineService] = None
audio_storage: Optional[AudioStorage] = None

# å†å²è®°å½•æ–‡ä»¶
HISTORY_FILE = os.path.join(FILE_CONFIG['output_dir'], 'history_records.json')

# çº¿ç¨‹å®‰å…¨çš„æ–‡ä»¶ç®¡ç†å™¨
class ThreadSafeFileManager:
    """çº¿ç¨‹å®‰å…¨çš„æ–‡ä»¶ç®¡ç†å™¨"""
    
    def __init__(self):
        self._files = []
        self._processing_files = []
        self._completed_files = []
        self._lock = threading.RLock()  # é€’å½’é”ï¼Œæ”¯æŒåŒä¸€çº¿ç¨‹å¤šæ¬¡è·å–
    
    def add_file(self, file_info: dict):
        """æ·»åŠ æ–‡ä»¶"""
        with self._lock:
            self._files.append(file_info)
    
    def get_file(self, file_id: str) -> Optional[dict]:
        """è·å–æ–‡ä»¶ä¿¡æ¯"""
        with self._lock:
            for f in self._files:
                if f['id'] == file_id:
                    return f
            return None
    
    def get_all_files(self) -> List[dict]:
        """è·å–æ‰€æœ‰æ–‡ä»¶ï¼ˆè¿”å›å‰¯æœ¬ï¼‰"""
        with self._lock:
            return self._files.copy()
    
    def update_file(self, file_id: str, updates: dict):
        """æ›´æ–°æ–‡ä»¶ä¿¡æ¯"""
        with self._lock:
            for f in self._files:
                if f['id'] == file_id:
                    f.update(updates)
                    return True
            return False
    
    def remove_file(self, file_id: str) -> bool:
        """ç§»é™¤æ–‡ä»¶"""
        with self._lock:
            for i, f in enumerate(self._files):
                if f['id'] == file_id:
                    self._files.pop(i)
                    self._processing_files = [fid for fid in self._processing_files if fid != file_id]
                    self._completed_files = [fid for fid in self._completed_files if fid != file_id]
                    return True
            return False
    
    def add_to_processing(self, file_id: str):
        """æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—"""
        with self._lock:
            if file_id not in self._processing_files:
                self._processing_files.append(file_id)
    
    def remove_from_processing(self, file_id: str):
        """ä»å¤„ç†é˜Ÿåˆ—ç§»é™¤"""
        with self._lock:
            self._processing_files = [fid for fid in self._processing_files if fid != file_id]
    
    def add_to_completed(self, file_id: str):
        """æ·»åŠ åˆ°å·²å®Œæˆé˜Ÿåˆ—"""
        with self._lock:
            if file_id not in self._completed_files:
                self._completed_files.append(file_id)
    
    def get_processing_files(self) -> List[str]:
        """è·å–å¤„ç†ä¸­çš„æ–‡ä»¶IDåˆ—è¡¨"""
        with self._lock:
            return self._processing_files.copy()
    
    def get_completed_files(self) -> List[str]:
        """è·å–å·²å®Œæˆçš„æ–‡ä»¶IDåˆ—è¡¨"""
        with self._lock:
            return self._completed_files.copy()
    
    def to_dict(self) -> dict:
        """è½¬æ¢ä¸ºå­—å…¸ï¼ˆç”¨äºåºåˆ—åŒ–ï¼‰"""
        with self._lock:
            return {
                'files': self._files.copy(),
                'processing_files': self._processing_files.copy(),
                'completed_files': self._completed_files.copy()
            }

# ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„æ–‡ä»¶ç®¡ç†å™¨
uploaded_files_manager = ThreadSafeFileManager()

# çº¿ç¨‹æ± ç”¨äºå¹¶å‘å¤„ç†è½¬å†™ä»»åŠ¡ï¼ˆä»é…ç½®è¯»å–ï¼‰
from config import CONCURRENCY_CONFIG
TRANSCRIPTION_THREAD_POOL = ThreadPoolExecutor(
    max_workers=CONCURRENCY_CONFIG.get('transcription_workers', 5),
    thread_name_prefix='transcribe-worker'
)

# ä»»åŠ¡å­—å…¸ï¼šå­˜å‚¨ file_id -> Future çš„æ˜ å°„ï¼Œç”¨äºå–æ¶ˆä»»åŠ¡
transcription_tasks = {}  # {file_id: Future}
transcription_tasks_lock = threading.Lock()  # ä¿æŠ¤ä»»åŠ¡å­—å…¸çš„é”

# âš ï¸ ç§»é™¤å…¨å±€é” - æ¨¡å‹æ± å·²ç»å¤„ç†å¹¶å‘ï¼Œä¸å†éœ€è¦å…¨å±€é”


# ä¿å­˜ä¸»äº‹ä»¶å¾ªç¯å¼•ç”¨
_main_loop = None

def set_main_loop(loop):
    """è®¾ç½®ä¸»äº‹ä»¶å¾ªç¯å¼•ç”¨"""
    global _main_loop
    _main_loop = loop
    logger.info("ä¸»äº‹ä»¶å¾ªç¯å·²è®¾ç½®")

def send_ws_message_sync(file_id: str, status: str, progress: int = 0, message: str = "", **kwargs):
    """
    åœ¨åŒæ­¥ä»£ç ä¸­å‘é€WebSocketæ¶ˆæ¯çš„è¾…åŠ©å‡½æ•°
    é€šè¿‡asyncio.run_coroutine_threadsafeåœ¨äº‹ä»¶å¾ªç¯ä¸­æ‰§è¡Œå¼‚æ­¥ä»»åŠ¡
    """
    if _main_loop is None:
        logger.warning("ä¸»äº‹ä»¶å¾ªç¯æœªè®¾ç½®ï¼Œæ— æ³•å‘é€WebSocketæ¶ˆæ¯")
        return
    
    try:
        # åœ¨ä¸»äº‹ä»¶å¾ªç¯ä¸­è°ƒåº¦å¼‚æ­¥ä»»åŠ¡
        asyncio.run_coroutine_threadsafe(
            ws_manager.send_file_status(file_id, status, progress, message, kwargs),
            _main_loop
        )
    except Exception as e:
        logger.error(f"å‘é€WebSocketæ¶ˆæ¯å¤±è´¥: {e}")


def init_voice_gateway(service: PipelineService, storage: AudioStorage):
    """åˆå§‹åŒ–ç½‘å…³æœåŠ¡"""
    global pipeline_service, audio_storage
    pipeline_service = service
    audio_storage = storage
    # å¯åŠ¨æ—¶åŠ è½½å†å²è®°å½•
    load_history_from_file()


def load_history_from_file():
    """ä»æ–‡ä»¶åŠ è½½å†å²è®°å½•ï¼ˆåªåŠ è½½å·²å®Œæˆçš„ï¼Œä¸å½±å“å½“å‰æ­£åœ¨å¤„ç†çš„æ–‡ä»¶ï¼‰"""
    global uploaded_files_manager
    try:
        if os.path.exists(HISTORY_FILE):
            with open(HISTORY_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                completed_files_from_disk = data.get('files', [])
                
                # ä¿ç•™å½“å‰å†…å­˜ä¸­æœªå®Œæˆçš„æ–‡ä»¶
                all_files = uploaded_files_manager.get_all_files()
                current_incomplete_files = [f for f in all_files 
                                           if f['status'] in ['uploaded', 'processing', 'error']]
                
                # åˆå¹¶ï¼šæœªå®Œæˆçš„æ–‡ä»¶ + ç£ç›˜ä¸Šçš„å·²å®Œæˆæ–‡ä»¶
                # ä½¿ç”¨å­—å…¸å»é‡ï¼Œä»¥file_idä¸ºkey
                files_dict = {}
                
                # å…ˆæ·»åŠ æœªå®Œæˆçš„æ–‡ä»¶
                for f in current_incomplete_files:
                    files_dict[f['id']] = f
                
                # å†æ·»åŠ å·²å®Œæˆçš„æ–‡ä»¶ï¼ˆå¦‚æœæœ‰é‡å¤ï¼Œå·²å®Œæˆçš„ä¼šè¦†ç›–ï¼‰
                for f in completed_files_from_disk:
                    files_dict[f['id']] = f
                
                # é‡æ–°æ„å»ºç®¡ç†å™¨ï¼ˆéœ€è¦åœ¨é”å†…å®Œæˆï¼‰
                uploaded_files_manager._lock.acquire()
                try:
                    uploaded_files_manager._files = list(files_dict.values())
                    uploaded_files_manager._completed_files = data.get('completed_files', [])
                finally:
                    uploaded_files_manager._lock.release()
                
                logger.info(f"å·²åŠ è½½ {len(completed_files_from_disk)} æ¡å†å²è®°å½•ï¼Œå½“å‰æ€»æ–‡ä»¶æ•°: {len(files_dict)}")
    except Exception as e:
        logger.error(f"åŠ è½½å†å²è®°å½•å¤±è´¥: {e}")


def save_history_to_file():
    """ä¿å­˜å†å²è®°å½•åˆ°æ–‡ä»¶"""
    try:
        # åªä¿å­˜å·²å®Œæˆçš„æ–‡ä»¶è®°å½•
        all_files = uploaded_files_manager.get_all_files()
        completed_files = [f for f in all_files if f['status'] == 'completed']
        data = {
            'files': completed_files,
            'completed_files': uploaded_files_manager.get_completed_files()
        }
        with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        logger.info(f"å·²ä¿å­˜ {len(completed_files)} æ¡å†å²è®°å½•")
    except Exception as e:
        logger.error(f"ä¿å­˜å†å²è®°å½•å¤±è´¥: {e}")


def allowed_file(filename: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ ¼å¼"""
    ALLOWED_EXTENSIONS = {'mp3', 'wav', 'm4a', 'flac', 'aac', 'ogg', 'wma'}
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


def save_transcript_to_word(transcript_data, filename_prefix="transcript", language="zh", audio_filename=None, file_id=None):
    """å°†è½¬å½•ç»“æœä¿å­˜ä¸ºWordæ–‡æ¡£"""
    try:
        doc = Document()
        
        # å®šä¹‰é»‘è‰²ï¼ˆRGB(0,0,0)ï¼‰
        black_color = RGBColor(0, 0, 0)
        
        title = doc.add_heading('è¯­éŸ³è½¬æ–‡å­—ç»“æœ', 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        # è®¾ç½®æ ‡é¢˜ä¸ºå¾®è½¯é›…é»‘ï¼Œé»‘è‰²
        for run in title.runs:
            run.font.name = 'Microsoft YaHei'
            run.font.color.rgb = black_color
            run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å¾®è½¯é›…é»‘')
        doc.add_paragraph()
        
        info_table = doc.add_table(rows=3, cols=2)
        # æ¢å¤åŸæ¥çš„è¡¨æ ¼æ ·å¼
        info_table.style = 'Light Grid Accent 1'
        
        for row in info_table.rows:
            row.cells[0].width = Inches(1.5)
            row.cells[1].width = Inches(5.0)
        
        # è®¾ç½®è¡¨æ ¼ç¬¬ä¸€åˆ—ï¼ˆæ ‡ç­¾ï¼‰ä¸ºå®‹ä½“11å·åŠ ç²—ï¼Œé»‘è‰²ï¼Œå±…ä¸­
        info_table.rows[0].cells[0].text = 'ç”Ÿæˆæ—¶é—´'
        label_para = info_table.rows[0].cells[0].paragraphs[0]
        label_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        label_run = label_para.runs[0]
        label_run.bold = True
        label_run.font.size = Pt(11)
        label_run.font.name = 'SimSun'
        label_run.font.color.rgb = black_color
        label_run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
        
        # è®¾ç½®è¡¨æ ¼ç¬¬äºŒåˆ—ï¼ˆå€¼ï¼‰ä¸ºå®‹ä½“11å·åŠ ç²—ï¼Œé»‘è‰²ï¼Œå±…ä¸­
        info_table.rows[0].cells[1].text = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        value_para = info_table.rows[0].cells[1].paragraphs[0]
        value_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        value_run = value_para.runs[0]
        value_run.bold = True
        value_run.font.size = Pt(11)
        value_run.font.name = 'SimSun'
        value_run.font.color.rgb = black_color
        value_run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
        
        info_table.rows[1].cells[0].text = 'éŸ³é¢‘æ–‡ä»¶'
        label_para = info_table.rows[1].cells[0].paragraphs[0]
        label_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        label_run = label_para.runs[0]
        label_run.bold = True
        label_run.font.size = Pt(11)
        label_run.font.name = 'SimSun'
        label_run.font.color.rgb = black_color
        label_run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
        
        info_table.rows[1].cells[1].text = audio_filename or "æœªçŸ¥æ–‡ä»¶"
        value_para = info_table.rows[1].cells[1].paragraphs[0]
        value_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        value_run = value_para.runs[0]
        value_run.bold = True
        value_run.font.size = Pt(11)
        value_run.font.name = 'SimSun'
        value_run.font.color.rgb = black_color
        value_run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
        
        info_table.rows[2].cells[0].text = 'æ–‡æœ¬é•¿åº¦'
        label_para = info_table.rows[2].cells[0].paragraphs[0]
        label_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        label_run = label_para.runs[0]
        label_run.bold = True
        label_run.font.size = Pt(11)
        label_run.font.name = 'SimSun'
        label_run.font.color.rgb = black_color
        label_run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
        
        total_chars = sum(len(entry['text']) for entry in transcript_data)
        info_table.rows[2].cells[1].text = f"{total_chars} å­—ç¬¦"
        value_para = info_table.rows[2].cells[1].paragraphs[0]
        value_para.alignment = WD_ALIGN_PARAGRAPH.CENTER
        value_run = value_para.runs[0]
        value_run.bold = True
        value_run.font.size = Pt(11)
        value_run.font.name = 'SimSun'
        value_run.font.color.rgb = black_color
        value_run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
        
        doc.add_paragraph()
        
        for entry in transcript_data:
            speaker_para = doc.add_paragraph()
            speaker_run = speaker_para.add_run(entry['speaker'])
            speaker_run.bold = True
            speaker_run.font.size = Pt(12)
            speaker_run.font.name = 'SimSun'
            speaker_run.font.color.rgb = black_color
            speaker_run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
            # è®¾ç½®å‘è¨€äººæ®µè½çš„ä¸‹é—´è·ä¸º0ï¼Œä½¿å†…å®¹ç´§è·Ÿåœ¨åé¢
            speaker_para.paragraph_format.space_after = Pt(0)
            
            # å‡å°å‘è¨€äººå’Œå†…å®¹çš„é—´è·ï¼Œè®¾ç½®æ®µè½é—´è·ä¸º0
            text_para = doc.add_paragraph()
            text_para.paragraph_format.space_before = Pt(0)
            text_para.paragraph_format.space_after = Pt(0)
            text_run = text_para.add_run(entry['text'])
            text_run.font.size = Pt(12)
            text_run.font.name = 'SimSun'
            text_run.font.color.rgb = black_color
            text_run._element.rPr.rFonts.set(qn('w:eastAsia'), 'å®‹ä½“')
            
            # ä¸åŒå‘è¨€äººä¹‹é—´çš„é—´è·ä¿æŒæ­£å¸¸
            doc.add_paragraph()
        
        # âœ… ä¿®å¤ï¼šä½¿ç”¨å¾®ç§’çº§æ—¶é—´æˆ³ + file_id ç¡®ä¿æ–‡ä»¶åå”¯ä¸€æ€§
        # å¦‚æœä¸¤ä¸ªæ–‡ä»¶åœ¨åŒä¸€ç§’å†…å®Œæˆï¼Œä½¿ç”¨å¾®ç§’å¯ä»¥åŒºåˆ†
        # å¦‚æœæä¾›äº† file_idï¼Œä¹ŸåŠ å…¥æ–‡ä»¶åä¸­ï¼Œè¿›ä¸€æ­¥ç¡®ä¿å”¯ä¸€æ€§
        now = datetime.now()
        timestamp = now.strftime('%Y%m%d_%H%M%S_%f')  # åŒ…å«å¾®ç§’
        
        # å¦‚æœæä¾›äº† file_idï¼Œä½¿ç”¨å‰8ä¸ªå­—ç¬¦ä½œä¸ºå”¯ä¸€æ ‡è¯†
        if file_id:
            file_id_short = file_id.replace('-', '')[:8]  # ç§»é™¤è¿å­—ç¬¦ï¼Œå–å‰8ä½
            filename = f"{filename_prefix}_{timestamp}_{file_id_short}.docx"
        else:
            filename = f"{filename_prefix}_{timestamp}.docx"
        
        filepath = os.path.join(FILE_CONFIG['output_dir'], filename)
        
        doc.save(filepath)
        return filename, filepath
        
    except Exception as e:
        logger.error(f"ä¿å­˜Wordæ–‡æ¡£å¤±è´¥: {e}")
        return None, None


def generate_meeting_summary(transcript_data):
    """ä½¿ç”¨AIç”Ÿæˆä¼šè®®çºªè¦"""
    try:
        if not transcript_data:
            return None
        
        transcript_text = ""
        for entry in transcript_data:
            speaker = entry.get('speaker', 'æœªçŸ¥å‘è¨€äºº')
            text = entry.get('text', '')
            transcript_text += f"{speaker}: {text}\n\n"
        
        api_key = os.getenv('DEEPSEEK_API_KEY', os.getenv('OPENAI_API_KEY'))
        api_base = os.getenv('DEEPSEEK_API_BASE', os.getenv('OPENAI_API_BASE', 'https://api.deepseek.com'))
        
        if not api_key:
            logger.warning("æœªé…ç½®API KEYï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿")
            return generate_default_summary(transcript_data)
        
        client = OpenAI(api_key=api_key, base_url=api_base)
        
        prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹ä¼šè®®è½¬å½•å†…å®¹ï¼Œç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„ä¼šè®®çºªè¦ã€‚

ä¼šè®®è½¬å½•å†…å®¹ï¼š
{transcript_text}

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼ç”Ÿæˆä¼šè®®çºªè¦ï¼š

ã€è¡¨æ ¼å½¢å¼ã€‘
ä¼šè®®ä¸»é¢˜ï¼š[æ ¹æ®ä¼šè®®å†…å®¹æ€»ç»“ä¸»é¢˜]
ä¼šè®®æ—¶é—´ï¼š[ä»è½¬å½•ä¸­æå–æˆ–æ¨æ–­æ—¶é—´]
ä¼šè®®åœ°ç‚¹ï¼š[ä»è½¬å½•ä¸­æå–æˆ–æ¨æ–­åœ°ç‚¹]
ä¸»æŒäººï¼š[ä»è½¬å½•ä¸­è¯†åˆ«ä¸»æŒäºº]
è®°å½•äººï¼šç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ
å‚ä¸äººå‘˜ï¼š[ä»è½¬å½•ä¸­è¯†åˆ«æ‰€æœ‰å‚ä¸è€…ï¼Œç”¨é¡¿å·åˆ†éš”]

ã€æ­£æ–‡éƒ¨åˆ†ã€‘
ä¸€ã€ä¼šè®®è®®é¢˜åŠè®¨è®ºå†…å®¹
äºŒã€è¡ŒåŠ¨æ¸…å•ï¼ˆå¾…åŠäº‹é¡¹ï¼‰
ä¸‰ã€å…¶ä»–è¯´æ˜"""
        
        response = client.chat.completions.create(
            model=os.getenv('DEEPSEEK_MODEL', os.getenv('OPENAI_MODEL', 'deepseek-chat')),
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¼šè®®çºªè¦åŠ©æ‰‹"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=4000
        )
        
        summary = {
            'raw_text': response.choices[0].message.content,
            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'model': os.getenv('DEEPSEEK_MODEL', 'deepseek-chat'),
            'status': 'success'
        }
        
        return summary
        
    except Exception as e:
        logger.error(f"ç”Ÿæˆä¼šè®®çºªè¦å¤±è´¥: {e}")
        return {
            'raw_text': f"ç”Ÿæˆä¼šè®®çºªè¦æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
            'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'status': 'error',
            'error': str(e)
        }


def generate_default_summary(transcript_data):
    """ç”Ÿæˆé»˜è®¤ä¼šè®®çºªè¦"""
    speaker_stats = {}
    total_words = 0
    
    for entry in transcript_data:
        speaker = entry.get('speaker', 'æœªçŸ¥å‘è¨€äºº')
        text = entry.get('text', '')
        
        if speaker not in speaker_stats:
            speaker_stats[speaker] = {'count': 0, 'words': 0}
        
        speaker_stats[speaker]['count'] += 1
        speaker_stats[speaker]['words'] += len(text)
        total_words += len(text)
    
    summary_text = f"""## ä¼šè®®æ¦‚è¦
æœ¬æ¬¡ä¼šè®®å…±æœ‰{len(speaker_stats)}ä½å‚ä¸è€…ï¼Œä¼šè®®è®°å½•å…±{len(transcript_data)}æ®µå‘è¨€ï¼Œæ€»è®¡çº¦{total_words}å­—ã€‚

## å‚ä¸äººå‘˜
"""
    
    for speaker, stats in speaker_stats.items():
        summary_text += f"- {speaker}: å‘è¨€{stats['count']}æ¬¡\n"
    
    return {
        'raw_text': summary_text,
        'generated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'model': 'default_template',
        'status': 'success'
    }


def save_meeting_summary_to_word(transcript_data, summary_data, filename_prefix="meeting_summary"):
    """å°†ä¼šè®®çºªè¦ä¿å­˜ä¸ºWordæ–‡æ¡£"""
    try:
        doc = Document()
        
        # å®šä¹‰é»‘è‰²ï¼ˆRGB(0,0,0)ï¼‰
        black_color = RGBColor(0, 0, 0)
        
        title = doc.add_heading('ä¼šè®®çºªè¦', 0)
        title.alignment = WD_ALIGN_PARAGRAPH.CENTER
        # è®¾ç½®æ ‡é¢˜ä¸ºé»‘è‰²
        for run in title.runs:
            run.font.color.rgb = black_color
        
        # æ·»åŠ çºªè¦å†…å®¹ï¼Œæ‰€æœ‰æ–‡æœ¬è®¾ç½®ä¸ºé»‘è‰²
        for line in summary_data.get('raw_text', '').split('\n'):
            para = doc.add_paragraph(line)
            for run in para.runs:
                run.font.color.rgb = black_color
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{filename_prefix}_{timestamp}.docx"
        filepath = os.path.join(FILE_CONFIG['output_dir'], filename)
        
        doc.save(filepath)
        return filename, filepath
        
    except Exception as e:
        logger.error(f"ä¿å­˜ä¼šè®®çºªè¦Wordæ–‡æ¡£å¤±è´¥: {e}")
        return None, None


# ==================== APIè·¯ç”± ====================

# ==================== æ–¹æ¡ˆ1: ä¸€ç«™å¼è½¬å†™æ¥å£ ====================

@router.post("/transcribe_all")
async def transcribe_all(
    audio_files: Union[UploadFile, List[UploadFile]] = File(...),  # æ”¯æŒå•ä¸ªæˆ–å¤šä¸ªæ–‡ä»¶
    language: str = Form("zh"),
    hotword: str = Form(""),
    generate_summary: bool = Form(False),
    return_type: str = Form("json")  # json/file/both
):
    """
    ğŸ¯ ä¸€ç«™å¼éŸ³é¢‘è½¬å†™æ¥å£ï¼ˆä¿®å¤ç‰ˆï¼‰

    åŠŸèƒ½ï¼šä¸Šä¼ å•ä¸ª/å¤šä¸ªéŸ³é¢‘ + è½¬å†™ + ç”Ÿæˆçºªè¦ + è¿”å›ç»“æœ

    å‚æ•°ï¼š
    - audio_files: éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨ï¼ˆå¿…å¡«ï¼Œæ”¯æŒå•ä¸ªæˆ–å¤šä¸ªï¼‰
    - language: è¯­è¨€ç±»å‹ (zh/en/zh-en/zh-dialect)ï¼Œé»˜è®¤ zh
    - hotword: çƒ­è¯ï¼Œç©ºæ ¼åˆ†éš”ï¼Œé»˜è®¤ä¸ºç©º
    - generate_summary: æ˜¯å¦ç”Ÿæˆä¼šè®®çºªè¦ï¼Œé»˜è®¤ False
    - return_type: è¿”å›ç±»å‹ (json/file/both)ï¼Œé»˜è®¤ json
      - json: è¿”å›JSONæ ¼å¼çš„ç»“æœå’Œä¸‹è½½é“¾æ¥
      - file: ç›´æ¥è¿”å›Wordæ–‡æ¡£ï¼ˆå•æ–‡ä»¶ï¼‰æˆ–ZIPå‹ç¼©åŒ…ï¼ˆå¤šæ–‡ä»¶ï¼‰
      - both: è¿”å›JSONæ ¼å¼ï¼ŒåŒæ—¶åœ¨JSONä¸­åŒ…å«æ–‡ä»¶çš„base64ç¼–ç  â­

    è¿”å›ï¼š
    - return_type=json: è¿”å›JSONæ ¼å¼çš„è½¬å†™ç»“æœ
    - return_type=file: ç›´æ¥è¿”å›Wordæ–‡æ¡£æˆ–ZIPæ–‡ä»¶
    - return_type=both: è¿”å›JSONï¼ˆåŒ…å«è½¬å†™ç»“æœ + æ–‡ä»¶base64ç¼–ç ï¼‰
    """
    try:
        # æ ‡å‡†åŒ–è¾“å…¥ï¼šå°†å•ä¸ªæ–‡ä»¶è½¬æ¢ä¸ºåˆ—è¡¨
        if isinstance(audio_files, UploadFile):
            audio_files = [audio_files]
        
        # éªŒè¯è¾“å…¥
        if not audio_files:
            return JSONResponse({'success': False, 'message': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}, status_code=400)
        
        # éªŒè¯æ‰€æœ‰æ–‡ä»¶æ ¼å¼
        for audio_file in audio_files:
            if not audio_file.filename:
                return JSONResponse({'success': False, 'message': 'å­˜åœ¨ç©ºæ–‡ä»¶åçš„æ–‡ä»¶'}, status_code=400)
            if not allowed_file(audio_file.filename):
                return JSONResponse({
                    'success': False, 
                    'message': f'æ–‡ä»¶ {audio_file.filename} æ ¼å¼ä¸æ”¯æŒï¼Œæ”¯æŒ: mp3, wav, m4a, flac, aac, ogg, wma'
                }, status_code=400)
        
        logger.info(f"[ä¸€ç«™å¼è½¬å†™] æ¥æ”¶åˆ° {len(audio_files)} ä¸ªæ–‡ä»¶ï¼Œè¿”å›ç±»å‹: {return_type}")
        
        # ================== é˜¶æ®µ1: å…ˆä¿å­˜æ‰€æœ‰æ–‡ä»¶åˆ°ç£ç›˜ ==================
        logger.info(f"[ä¸€ç«™å¼è½¬å†™] é˜¶æ®µ1: ä¿å­˜ {len(audio_files)} ä¸ªæ–‡ä»¶...")
        files_to_process = []
        
        for idx, audio_file in enumerate(audio_files):
            try:
                # ä¿å­˜æ–‡ä»¶
                filename = secure_filename(audio_file.filename)
                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
                name, ext = os.path.splitext(filename)
                safe_filename = f"{name}_{timestamp}_{idx}{ext}"
                
                contents = await audio_file.read()
                file_size = len(contents)
                filepath = audio_storage.save_uploaded_file(contents, safe_filename)
                file_id = str(uuid.uuid4())
                
                file_info = {
                    'id': file_id,
                    'filename': safe_filename,
                    'original_name': audio_file.filename,
                    'filepath': filepath,
                    'size': file_size,
                    'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'status': 'processing',
                    'progress': 0,
                    'language': language,
                    'generate_summary': generate_summary,
                    'hotword': hotword
                }
                
                uploaded_files_manager.add_file(file_info)
                uploaded_files_manager.add_to_processing(file_id)
                files_to_process.append(file_info)
                
                # WebSocketé€šçŸ¥
                send_ws_message_sync(file_id, 'processing', 0, f"å·²ä¸Šä¼ ï¼Œç­‰å¾…è½¬å†™: {audio_file.filename}")
                logger.info(f"[ä¸€ç«™å¼è½¬å†™] å·²ä¿å­˜ {idx+1}/{len(audio_files)}: {audio_file.filename}")
                
            except Exception as e:
                logger.error(f"[ä¸€ç«™å¼è½¬å†™] ä¿å­˜æ–‡ä»¶ {audio_file.filename} å¤±è´¥: {e}")
        
        if not files_to_process:
            return JSONResponse({'success': False, 'message': 'æ‰€æœ‰æ–‡ä»¶ä¿å­˜å¤±è´¥'}, status_code=500)
        
        logger.info(f"[ä¸€ç«™å¼è½¬å†™] é˜¶æ®µ1å®Œæˆï¼ŒæˆåŠŸä¿å­˜ {len(files_to_process)} ä¸ªæ–‡ä»¶")
        
        # ================== é˜¶æ®µ2: ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†æ‰€æœ‰æ–‡ä»¶ ==================
        import time as _time_module
        batch_start_time = _time_module.time()
        
        logger.info(f"[ä¸€ç«™å¼è½¬å†™] é˜¶æ®µ2: å¹¶å‘è½¬å†™ {len(files_to_process)} ä¸ªæ–‡ä»¶")
        logger.info(f"[ä¸€ç«™å¼è½¬å†™] çº¿ç¨‹æ± é…ç½®: max_workers={CONCURRENCY_CONFIG['transcription_workers']}, æ¨¡å‹æ± ={CONCURRENCY_CONFIG['asr_pool_size']}")
        
        # å…±äº«ç»“æœå®¹å™¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
        all_results = []
        all_word_files = []
        results_lock = threading.Lock()
        
        # å¹¶å‘åº¦é‡æŒ‡æ ‡
        concurrent_metrics = {
            'active_count': 0,
            'completed_count': 0,
            'failed_count': 0,
            'max_concurrent': 0,
            'start_times': {},
            'completion_times': {}
        }
        metrics_lock = threading.Lock()
        
        # å®šä¹‰å•æ–‡ä»¶å¤„ç†å‡½æ•°
        def process_single_file_for_batch(file_info):
            file_id = file_info['id']
            original_name = file_info['original_name']
            file_start_time = _time_module.time()
            
            try:
                # æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
                if file_info.get('_cancelled', False):
                    logger.info(f"[ä¸€ç«™å¼è½¬å†™-å¹¶å‘] æ–‡ä»¶ {file_id} å·²è¢«å–æ¶ˆï¼Œè·³è¿‡å¤„ç†")
                    file_info['status'] = 'uploaded'
                    file_info['progress'] = 0
                    return
                
                # ğŸ“Š è®°å½•å¼€å§‹ - æ›´æ–°å¹¶å‘åº¦é‡
                with metrics_lock:
                    concurrent_metrics['active_count'] += 1
                    concurrent_metrics['start_times'][file_id] = file_start_time
                    if concurrent_metrics['active_count'] > concurrent_metrics['max_concurrent']:
                        concurrent_metrics['max_concurrent'] = concurrent_metrics['active_count']
                
                logger.info(f"[ä¸€ç«™å¼è½¬å†™-å¹¶å‘] å¼€å§‹å¤„ç†: {original_name} (çº¿ç¨‹: {threading.current_thread().name}, å½“å‰å¹¶å‘: {concurrent_metrics['active_count']})")
                
                # åˆ›å»ºè¿›åº¦å›è°ƒ
                def update_progress(step, progress, message="", transcript_entry=None):
                    # æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
                    if file_info.get('_cancelled', False):
                        logger.info(f"[ä¸€ç«™å¼è½¬å†™-å¹¶å‘] æ£€æµ‹åˆ°æ–‡ä»¶ {file_id} å·²è¢«å–æ¶ˆï¼Œåœæ­¢å¤„ç†")
                        raise InterruptedError("è½¬å†™ä»»åŠ¡å·²è¢«å–æ¶ˆ")
                    
                    file_info['progress'] = progress
                    send_ws_message_sync(file_id, 'processing', progress, message or f"å¤„ç†ä¸­: {step}")
                
                # æ‰§è¡Œè½¬å†™
                pipeline_service.set_callback(update_progress)
                transcript, _, _ = pipeline_service.execute_transcription(
                    file_info['filepath'],
                    hotword=file_info['hotword'],
                    language=file_info['language'],
                    instance_id=file_id,
                    cancellation_flag=lambda: file_info.get('_cancelled', False)  # ä¼ é€’å–æ¶ˆæ£€æŸ¥å‡½æ•°
                )
                
                # æ£€æŸ¥æ˜¯å¦åœ¨è½¬å†™è¿‡ç¨‹ä¸­è¢«å–æ¶ˆ
                if file_info.get('_cancelled', False):
                    logger.info(f"[ä¸€ç«™å¼è½¬å†™-å¹¶å‘] æ–‡ä»¶ {file_id} åœ¨è½¬å†™è¿‡ç¨‹ä¸­è¢«å–æ¶ˆ")
                    file_info['status'] = 'uploaded'
                    file_info['progress'] = 0
                    file_info['error_message'] = 'è½¬å†™å·²åœæ­¢'
                    send_ws_message_sync(file_id, 'uploaded', 0, 'è½¬å†™å·²åœæ­¢')
                    with metrics_lock:
                        concurrent_metrics['active_count'] -= 1
                    return
                
                if not transcript:
                    logger.warning(f"[ä¸€ç«™å¼è½¬å†™-å¹¶å‘] æ–‡ä»¶ {original_name} è½¬å†™å¤±è´¥")
                    file_info['status'] = 'error'
                    file_info['error_message'] = 'è½¬å†™å¤±è´¥'
                    send_ws_message_sync(file_id, 'error', 0, 'è½¬å†™å¤±è´¥')
                    
                    # ğŸ“Š è®°å½•å¤±è´¥
                    with metrics_lock:
                        concurrent_metrics['active_count'] -= 1
                        concurrent_metrics['failed_count'] += 1
                    
                    with results_lock:
                        all_results.append({
                            'success': False,
                            'filename': original_name,
                            'file_id': file_id,
                            'error': 'è½¬å†™å¤±è´¥'
                        })
                    return
                
                file_info['transcript_data'] = transcript
                
                # ä¿å­˜è½¬å†™æ–‡æ¡£
                # âœ… ä¿®å¤ï¼šä¼ å…¥ file_id ç¡®ä¿æ¯ä¸ªæ–‡ä»¶ç”Ÿæˆå”¯ä¸€çš„è½¬å†™æ–‡æ¡£æ–‡ä»¶å
                transcript_filename, transcript_filepath = save_transcript_to_word(
                    transcript,
                    language=file_info['language'],
                    audio_filename=original_name,
                    file_id=file_id
                )
                
                if transcript_filename:
                    file_info['transcript_file'] = transcript_filepath
                    with results_lock:
                        all_word_files.append(transcript_filepath)
                    logger.info(f"[ä¸€ç«™å¼è½¬å†™-å¹¶å‘] è½¬å†™æ–‡æ¡£å·²ä¿å­˜: {transcript_filename}")
                
                # ç”Ÿæˆä¼šè®®çºªè¦ï¼ˆå¯é€‰ï¼‰
                summary = None
                if file_info['generate_summary']:
                    logger.info(f"[ä¸€ç«™å¼è½¬å†™-å¹¶å‘] ç”Ÿæˆä¼šè®®çºªè¦: {original_name}")
                    summary = generate_meeting_summary(transcript)
                    if summary:
                        file_info['meeting_summary'] = summary
                        name, _ = os.path.splitext(file_info['filename'])
                        summary_filename, summary_filepath = save_meeting_summary_to_word(
                            transcript, summary, filename_prefix=f"summary_{name}"
                        )
                        if summary_filepath:
                            with results_lock:
                                all_word_files.append(summary_filepath)
                            logger.info(f"[ä¸€ç«™å¼è½¬å†™-å¹¶å‘] ä¼šè®®çºªè¦å·²ä¿å­˜: {summary_filename}")
                
                # æ›´æ–°çŠ¶æ€
                file_info['status'] = 'completed'
                file_info['progress'] = 100
                file_info['complete_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
                if file_id not in uploaded_files_manager.get_completed_files():
                    uploaded_files_manager.add_to_completed(file_id)
                
                if file_id in uploaded_files_manager.get_processing_files():
                    uploaded_files_manager.remove_from_processing(file_id)
                
                save_history_to_file()
                send_ws_message_sync(file_id, 'completed', 100, 'è½¬å†™å®Œæˆ')
                
                # ç»Ÿè®¡ä¿¡æ¯
                speakers = set(t.get('speaker', '') for t in transcript if t.get('speaker'))
                total_duration = transcript[-1].get('end_time', 0) if transcript else 0
                
                # æ„å»ºå•ä¸ªæ–‡ä»¶ç»“æœ
                file_result = {
                    'success': True,
                    'file_id': file_id,
                    'filename': original_name,
                    'file_info': {
                        'id': file_id,
                        'filename': original_name,
                        'upload_time': file_info['upload_time'],
                        'complete_time': file_info['complete_time'],
                        'size': file_info['size'],
                        'language': file_info['language']
                    },
                    'transcript': transcript,
                    'download_urls': {
                        'audio': f"/api/voice/audio/{file_id}?download=1",
                        'transcript': f"/api/voice/download_transcript/{file_id}"
                    },
                    'statistics': {
                        'speakers_count': len(speakers),
                        'segments_count': len(transcript),
                        'total_duration': round(total_duration, 2),
                        'total_characters': sum(len(t.get('text', '')) for t in transcript),
                        'speakers': list(speakers)
                    }
                }
                
                if summary:
                    file_result['summary'] = summary
                    file_result['download_urls']['summary'] = f"/api/voice/download_summary/{file_id}"
                
                with results_lock:
                    all_results.append(file_result)
                
                # ğŸ“Š è®°å½•æˆåŠŸå®Œæˆ
                file_duration = _time_module.time() - file_start_time
                with metrics_lock:
                    concurrent_metrics['active_count'] -= 1
                    concurrent_metrics['completed_count'] += 1
                    concurrent_metrics['completion_times'][file_id] = file_duration
                
                logger.info(f"[ä¸€ç«™å¼è½¬å†™-å¹¶å‘] âœ… å®Œæˆ: {original_name} (è€—æ—¶: {file_duration:.1f}ç§’, å‰©ä½™æ´»è·ƒ: {concurrent_metrics['active_count']})")
                
            except InterruptedError as e:
                # å¤„ç†ä¸­æ–­å¼‚å¸¸
                logger.info(f"[ä¸€ç«™å¼è½¬å†™-å¹¶å‘] æ–‡ä»¶ {file_id} è½¬å†™è¢«ä¸­æ–­: {e}")
                file_info['status'] = 'uploaded'
                file_info['progress'] = 0
                file_info['error_message'] = 'è½¬å†™å·²åœæ­¢'
                send_ws_message_sync(file_id, 'uploaded', 0, 'è½¬å†™å·²åœæ­¢')
                with metrics_lock:
                    concurrent_metrics['active_count'] -= 1
            except Exception as e:
                file_id = file_info['id']
                logger.error(f"[ä¸€ç«™å¼è½¬å†™-å¹¶å‘] âŒ å¤„ç†æ–‡ä»¶ {file_info['original_name']} å¤±è´¥: {e}")
                
                # å¦‚æœæ˜¯å› ä¸ºå–æ¶ˆå¯¼è‡´çš„å¼‚å¸¸ï¼Œä¸æ ‡è®°ä¸ºé”™è¯¯
                if file_info.get('_cancelled', False):
                    file_info['status'] = 'uploaded'
                    file_info['progress'] = 0
                    file_info['error_message'] = 'è½¬å†™å·²åœæ­¢'
                    send_ws_message_sync(file_id, 'uploaded', 0, 'è½¬å†™å·²åœæ­¢')
                    with metrics_lock:
                        concurrent_metrics['active_count'] -= 1
                else:
                    import traceback
                    traceback.print_exc()
                    
                    # ğŸ“Š è®°å½•å¤±è´¥
                    with metrics_lock:
                        concurrent_metrics['active_count'] -= 1
                        concurrent_metrics['failed_count'] += 1
                    
                    with results_lock:
                        all_results.append({
                            'success': False,
                            'filename': file_info['original_name'],
                            'file_id': file_id,
                            'error': str(e)
                        })
            finally:
                # ä»ä»»åŠ¡å­—å…¸ä¸­ç§»é™¤
                file_id = file_info['id']
                with transcription_tasks_lock:
                    if file_id in transcription_tasks:
                        del transcription_tasks[file_id]
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æäº¤æ‰€æœ‰ä»»åŠ¡
        futures = []
        for file_info in files_to_process:
            file_id = file_info['id']
            # åˆå§‹åŒ–å–æ¶ˆæ ‡å¿—
            file_info['_cancelled'] = False
            
            future = TRANSCRIPTION_THREAD_POOL.submit(process_single_file_for_batch, file_info)
            futures.append(future)
            
            # å°†Futureå­˜å‚¨åˆ°ä»»åŠ¡å­—å…¸ä¸­ï¼Œç”¨äºå–æ¶ˆä»»åŠ¡
            with transcription_tasks_lock:
                transcription_tasks[file_id] = future
        
        logger.info(f"[ä¸€ç«™å¼è½¬å†™] ğŸ“¤ å·²æäº¤ {len(futures)} ä¸ªä»»åŠ¡åˆ°çº¿ç¨‹æ± å¹¶å‘å¤„ç†")

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        # âš ï¸ ä¿®å¤ï¼šä½¿ç”¨ asyncio.to_thread é¿å…é˜»å¡äº‹ä»¶å¾ªç¯
        def wait_futures():
            wait(futures, timeout=3600)  # æœ€å¤šç­‰å¾…1å°æ—¶ï¼ˆå‡å°‘è¶…æ—¶æ—¶é—´ï¼‰

        try:
            await asyncio.to_thread(wait_futures)
        except Exception as e:
            logger.warning(f"[ä¸€ç«™å¼è½¬å†™] ç­‰å¾…ä»»åŠ¡å®Œæˆæ—¶å‡ºé”™: {e}ï¼Œç»§ç»­å¤„ç†å·²å®Œæˆçš„ä»»åŠ¡")
        
        # è®¡ç®—æ€»è€—æ—¶å’Œæ€§èƒ½æŒ‡æ ‡
        batch_duration = _time_module.time() - batch_start_time
        
        logger.info(f"[ä¸€ç«™å¼è½¬å†™] ==================== æ‰¹å¤„ç†å®Œæˆ ====================")
        logger.info(f"[ä¸€ç«™å¼è½¬å†™] ğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        logger.info(f"[ä¸€ç«™å¼è½¬å†™]   - æ€»æ–‡ä»¶æ•°: {len(files_to_process)}")
        logger.info(f"[ä¸€ç«™å¼è½¬å†™]   - æˆåŠŸ: {concurrent_metrics['completed_count']}, å¤±è´¥: {concurrent_metrics['failed_count']}")
        logger.info(f"[ä¸€ç«™å¼è½¬å†™]   - æœ€å¤§å¹¶å‘æ•°: {concurrent_metrics['max_concurrent']}")
        logger.info(f"[ä¸€ç«™å¼è½¬å†™]   - æ€»è€—æ—¶: {batch_duration:.2f}ç§’")
        
        if concurrent_metrics['completion_times']:
            avg_time = sum(concurrent_metrics['completion_times'].values()) / len(concurrent_metrics['completion_times'])
            max_time = max(concurrent_metrics['completion_times'].values())
            min_time = min(concurrent_metrics['completion_times'].values())
            logger.info(f"[ä¸€ç«™å¼è½¬å†™]   - å•æ–‡ä»¶å¹³å‡: {avg_time:.2f}ç§’, æœ€å¿«: {min_time:.2f}ç§’, æœ€æ…¢: {max_time:.2f}ç§’")
            logger.info(f"[ä¸€ç«™å¼è½¬å†™]   - å¹¶å‘åŠ é€Ÿæ¯”: {(avg_time * len(files_to_process)) / batch_duration:.2f}x")
        
        logger.info(f"[ä¸€ç«™å¼è½¬å†™] ==================================================")
        
        # ç»Ÿè®¡
        success_count = sum(1 for r in all_results if r.get('success'))
        failed_count = len(all_results) - success_count
        
        logger.info(f"[ä¸€ç«™å¼è½¬å†™] å…¨éƒ¨å®Œæˆ: æˆåŠŸ {success_count}/{len(audio_files)}")
        
        # æ ¹æ® return_type è¿”å›ä¸åŒæ ¼å¼
        if return_type == "file":
            # ç›´æ¥è¿”å›æ–‡ä»¶
            if not all_word_files:
                return JSONResponse({
                    'success': False,
                    'message': 'æ‰€æœ‰æ–‡ä»¶è½¬å†™å¤±è´¥',
                    'results': all_results
                }, status_code=500)
            
            # å•ä¸ªæ–‡ä»¶ï¼šç›´æ¥è¿”å›Wordæ–‡æ¡£
            if len(all_word_files) == 1:
                return FileResponse(
                    path=all_word_files[0],
                    filename=os.path.basename(all_word_files[0]),
                    media_type='application/vnd.openxmlformats-officedocument.wordprocessingml.document'
                )
            
            # å¤šä¸ªæ–‡ä»¶ï¼šæ‰“åŒ…æˆZIPè¿”å›
            zip_filename = f"transcripts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
            zip_path = os.path.join(FILE_CONFIG['output_dir'], zip_filename)
            
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file_path in all_word_files:
                    if os.path.exists(file_path):
                        arcname = os.path.basename(file_path)
                        zipf.write(file_path, arcname)
                        logger.info(f"[ä¸€ç«™å¼è½¬å†™] æ·»åŠ åˆ°ZIP: {arcname}")
            
            logger.info(f"[ä¸€ç«™å¼è½¬å†™] ZIPåˆ›å»ºæˆåŠŸ: {zip_filename}")
            
            return FileResponse(
                path=zip_path,
                filename=zip_filename,
                media_type='application/zip',
                headers={
                    'X-Success-Count': str(success_count),
                    'X-Failed-Count': str(failed_count),
                    'X-Total-Files': str(len(all_word_files))
                }
            )
        
        elif return_type == "both":
            # bothæ¨¡å¼ï¼šè¿”å›JSON + æ–‡ä»¶base64ç¼–ç 
            logger.info(f"[ä¸€ç«™å¼è½¬å†™] BOTHæ¨¡å¼ï¼šå‡†å¤‡ç¼–ç  {len(all_word_files)} ä¸ªæ–‡ä»¶")
            
            files_data = []
            
            # å•ä¸ªæ–‡ä»¶æ—¶ï¼Œç›´æ¥ç¼–ç Wordæ–‡æ¡£
            if len(all_word_files) == 1 and all_word_files[0]:
                try:
                    with open(all_word_files[0], 'rb') as f:
                        file_content = f.read()
                        file_base64 = base64.b64encode(file_content).decode('utf-8')
                        files_data.append({
                            'filename': os.path.basename(all_word_files[0]),
                            'content_base64': file_base64,
                            'size': len(file_content),
                            'mime_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
                        })
                        logger.info(f"[ä¸€ç«™å¼è½¬å†™] å·²ç¼–ç æ–‡ä»¶: {os.path.basename(all_word_files[0])}")
                except Exception as e:
                    logger.error(f"[ä¸€ç«™å¼è½¬å†™] ç¼–ç æ–‡ä»¶å¤±è´¥: {e}")
            
            # å¤šä¸ªæ–‡ä»¶æ—¶ï¼Œæ‰“åŒ…æˆZIPå†ç¼–ç 
            elif len(all_word_files) > 1:
                try:
                    zip_filename = f"transcripts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
                    zip_path = os.path.join(FILE_CONFIG['output_dir'], zip_filename)
                    
                    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                        for file_path in all_word_files:
                            if os.path.exists(file_path):
                                arcname = os.path.basename(file_path)
                                zipf.write(file_path, arcname)
                    
                    with open(zip_path, 'rb') as f:
                        zip_content = f.read()
                        zip_base64 = base64.b64encode(zip_content).decode('utf-8')
                        files_data.append({
                            'filename': zip_filename,
                            'content_base64': zip_base64,
                            'size': len(zip_content),
                            'mime_type': 'application/zip'
                        })
                        logger.info(f"[ä¸€ç«™å¼è½¬å†™] å·²ç¼–ç ZIPæ–‡ä»¶: {zip_filename}, å¤§å°: {len(zip_content)} bytes")
                except Exception as e:
                    logger.error(f"[ä¸€ç«™å¼è½¬å†™] åˆ›å»ºZIPå¤±è´¥: {e}")
            
            # è¿”å›JSONå“åº”ï¼ˆåŒ…å«è½¬å†™ç»“æœå’Œæ–‡ä»¶ï¼‰
            response_data = {
                'success': success_count > 0,
                'message': f'å¤„ç†å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}',
                'total_files': len(audio_files),
                'success_count': success_count,
                'failed_count': failed_count,
                'results': all_results,
                'files': files_data  # â­ åŒ…å«æ–‡ä»¶çš„base64ç¼–ç 
            }
            
            # æ·»åŠ ä¸‹è½½é“¾æ¥ï¼ˆæ–¹ä¾¿ç”¨æˆ·ç›´æ¥ä¸‹è½½ï¼‰
            if files_data:
                response_data['download_urls'] = []
                for file_info in files_data:
                    response_data['download_urls'].append({
                        'filename': file_info['filename'],
                        'url': f"/api/voice/download_file/{file_info['filename']}",
                        'size': file_info['size']
                    })
            
            logger.info(f"[ä¸€ç«™å¼è½¬å†™] è¿”å›æ•°æ®: filesæ•°é‡={len(files_data)}")
            return response_data
        
        else:
            # return_type == "json"ï¼Œè¿”å›JSONå“åº”ï¼ˆåŒ…å«æ€§èƒ½æŒ‡æ ‡ï¼‰
            return {
                'success': success_count > 0,
                'message': f'å¤„ç†å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}',
                'total_files': len(audio_files),
                'success_count': success_count,
                'failed_count': failed_count,
                'results': all_results,
                'performance': {
                    'batch_duration': round(batch_duration, 2),
                    'max_concurrent': concurrent_metrics['max_concurrent'],
                    'avg_file_time': round(sum(concurrent_metrics['completion_times'].values()) / len(concurrent_metrics['completion_times']), 2) if concurrent_metrics['completion_times'] else 0,
                    'speedup_ratio': round((sum(concurrent_metrics['completion_times'].values())) / batch_duration, 2) if batch_duration > 0 and concurrent_metrics['completion_times'] else 1.0
                }
            }
        
    except Exception as e:
        logger.error(f"[ä¸€ç«™å¼è½¬å†™] å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        # æ¸…ç†èµ„æº
        if 'file_info' in locals() and file_info:
            file_info['status'] = 'error'
            file_info['error_message'] = str(e)
            if file_id in uploaded_files_manager.get_processing_files():
                uploaded_files_manager.remove_from_processing(file_id)
        
        return JSONResponse({
            'success': False,
            'message': f'å¤„ç†å¤±è´¥: {str(e)}'
        }, status_code=500)


# ==================== æ–¹æ¡ˆ2: RESTfulæ–‡ä»¶èµ„æºæ¥å£ ====================

@router.get("/files")
async def list_all_files(
    filepath: Optional[str] = None,
    status: Optional[str] = None,
    limit: Optional[int] = None,
    offset: int = 0,
    include_history: bool = False,
    download: int = 0
):
    """
    ğŸ“‹ åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶ï¼ˆRESTfulé£æ ¼ï¼Œæ–¹æ¡ˆ2ä¼˜åŒ–ï¼‰
    
    æŸ¥è¯¢å‚æ•°ï¼š
    - filepath: å¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ç›´æ¥è¿”å›è¯¥è·¯å¾„çš„éŸ³é¢‘æ–‡ä»¶ï¼ˆç±»ä¼¼ /api/voice/files/{file_id}ï¼‰
    - status: è¿‡æ»¤çŠ¶æ€ (uploaded/processing/completed/error)
    - limit: è¿”å›æ•°é‡é™åˆ¶
    - offset: åˆ†é¡µåç§»é‡
    - include_history: æ˜¯å¦åŒ…å«å†å²è®°å½•ï¼Œé»˜è®¤False
    - download: å½“æä¾›filepathæ—¶ï¼Œæ˜¯å¦ä¸‹è½½ï¼ˆ0=é¢„è§ˆï¼Œ1=ä¸‹è½½ï¼‰
    
    è¿”å›ï¼šæ–‡ä»¶åˆ—è¡¨åŠç»Ÿè®¡ä¿¡æ¯ï¼Œæˆ–éŸ³é¢‘æ–‡ä»¶ï¼ˆå½“æä¾›filepathæ—¶ï¼‰
    """
    try:
        # å¦‚æœæä¾›äº†filepathï¼Œç›´æ¥è¿”å›éŸ³é¢‘æ–‡ä»¶
        if filepath:
            # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢è·¯å¾„éå†æ”»å‡»
            # è§„èŒƒåŒ–è·¯å¾„å¹¶ç¡®ä¿åœ¨å…è®¸çš„ç›®å½•å†…
            normalized_path = os.path.normpath(filepath)
            
            # æ£€æŸ¥è·¯å¾„æ˜¯å¦åœ¨uploadsç›®å½•å†…
            upload_dir = os.path.abspath(FILE_CONFIG['upload_dir'])
            file_full_path = os.path.abspath(normalized_path)
            
            # ç¡®ä¿æ–‡ä»¶è·¯å¾„åœ¨uploadsç›®å½•å†…
            if not file_full_path.startswith(upload_dir):
                raise HTTPException(status_code=403, detail="æ–‡ä»¶è·¯å¾„ä¸åœ¨å…è®¸çš„ç›®å½•å†…")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(file_full_path):
                raise HTTPException(status_code=404, detail="éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
            
            # æ£€æŸ¥æ˜¯å¦ä¸ºæ–‡ä»¶ï¼ˆä¸æ˜¯ç›®å½•ï¼‰
            if not os.path.isfile(file_full_path):
                raise HTTPException(status_code=400, detail="æŒ‡å®šè·¯å¾„ä¸æ˜¯æ–‡ä»¶")
            
            # è·å–æ–‡ä»¶åï¼ˆç”¨äºä¸‹è½½æ—¶çš„æ–‡ä»¶åï¼‰
            filename = os.path.basename(file_full_path)
            
            if download == 1:
                return FileResponse(
                    file_full_path,
                    media_type='application/octet-stream',
                    filename=filename
                )
            else:
                return FileResponse(
                    file_full_path,
                    media_type='audio/mpeg'
                )
        
        # å¦‚æœéœ€è¦å†å²è®°å½•ï¼Œä»æ–‡ä»¶åŠ è½½
        if include_history:
            load_history_from_file()
        
        # è·å–æ‰€æœ‰æ–‡ä»¶
        all_files = uploaded_files_manager.get_all_files()
        
        # æ ¹æ®çŠ¶æ€è¿‡æ»¤
        if status:
            filtered_files = [f for f in all_files if f['status'] == status]
        else:
            filtered_files = all_files
        
        # æ’åºï¼šprocessing > uploaded > completed > error
        status_priority = {'processing': 0, 'uploaded': 1, 'completed': 2, 'error': 3}
        filtered_files.sort(key=lambda x: (
            status_priority.get(x['status'], 999),
            x.get('upload_time', '')
        ), reverse=True)
        
        # åˆ†é¡µ
        total_count = len(filtered_files)
        if limit:
            filtered_files = filtered_files[offset:offset+limit]
        else:
            filtered_files = filtered_files[offset:]
        
        # ğŸ”§ ä¸ºæ¯ä¸ªæ–‡ä»¶æ·»åŠ å¯è®¿é—®çš„ä¸‹è½½URL
        for file_info in filtered_files:
            # æ·»åŠ éŸ³é¢‘ä¸‹è½½é“¾æ¥
            if 'download_urls' not in file_info:
                file_info['download_urls'] = {}
            file_info['download_urls']['audio'] = f"/api/voice/audio/{file_info['id']}?download=1"
            
            # æ·»åŠ è½¬å†™æ–‡æ¡£ä¸‹è½½é“¾æ¥ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if file_info.get('transcript_file'):
                file_info['download_urls']['transcript'] = f"/api/voice/download_transcript/{file_info['id']}"
            
            # æ·»åŠ ä¼šè®®çºªè¦ä¸‹è½½é“¾æ¥ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if file_info.get('meeting_summary'):
                file_info['download_urls']['summary'] = f"/api/voice/download_summary/{file_info['id']}"
        
        # ç»Ÿè®¡ä¿¡æ¯
        status_counts = {
            'uploaded': len([f for f in all_files if f['status'] == 'uploaded']),
            'processing': len([f for f in all_files if f['status'] == 'processing']),
            'completed': len([f for f in all_files if f['status'] == 'completed']),
            'error': len([f for f in all_files if f['status'] == 'error'])
        }
        
        return {
            'success': True,
            'files': filtered_files,
            'pagination': {
                'total': total_count,
                'limit': limit,
                'offset': offset,
                'returned': len(filtered_files)
            },
            'statistics': status_counts
        }
        
    except Exception as e:
        logger.error(f"åˆ—å‡ºæ–‡ä»¶å¤±è´¥: {e}")
        return JSONResponse({
            'success': False,
            'message': f'è·å–æ–‡ä»¶åˆ—è¡¨å¤±è´¥: {str(e)}'
        }, status_code=500)


@router.get("/files/{file_id}")
async def get_file_detail(
    file_id: str,
    include_transcript: bool = False,
    include_summary: bool = False
):
    """
    ğŸ“„ è·å–æ–‡ä»¶è¯¦æƒ…ï¼ˆRESTfulé£æ ¼ï¼Œæ–¹æ¡ˆ2ä¼˜åŒ–ï¼‰
    
    è·¯å¾„å‚æ•°ï¼š
    - file_id: æ–‡ä»¶ID
    
    æŸ¥è¯¢å‚æ•°ï¼š
    - include_transcript: æ˜¯å¦åŒ…å«è½¬å†™ç»“æœï¼Œé»˜è®¤False
    - include_summary: æ˜¯å¦åŒ…å«ä¼šè®®çºªè¦ï¼Œé»˜è®¤False
    
    è¿”å›ï¼šæ–‡ä»¶è¯¦ç»†ä¿¡æ¯
    """
    try:
        file_info = next((f for f in uploaded_files_manager.get_all_files() if f['id'] == file_id), None)
        
        if not file_info:
            raise HTTPException(status_code=404, detail='æ–‡ä»¶ä¸å­˜åœ¨')
        
        # æ„å»ºåŸºæœ¬å“åº”
        result = {
            'success': True,
            'file': {
                'id': file_info['id'],
                'filename': file_info.get('original_name', file_info.get('filename')),
                'size': file_info.get('size', 0),
                'status': file_info['status'],
                'progress': file_info.get('progress', 0),
                'language': file_info.get('language', 'zh'),
                'upload_time': file_info.get('upload_time'),
                'complete_time': file_info.get('complete_time'),
                'error_message': file_info.get('error_message', '')
            }
        }
        
        # æ·»åŠ ä¸‹è½½é“¾æ¥
        result['file']['download_urls'] = {
            'audio': f"/api/voice/audio/{file_id}?download=1"
        }
        
        if file_info.get('transcript_file'):
            result['file']['download_urls']['transcript'] = f"/api/voice/download_transcript/{file_id}"
        
        if file_info.get('meeting_summary'):
            result['file']['download_urls']['summary'] = f"/api/voice/download_summary/{file_id}"
        
        # å¯é€‰ï¼šåŒ…å«è½¬å†™ç»“æœ
        if include_transcript and file_info['status'] == 'completed':
            transcript_data = file_info.get('transcript_data', [])
            result['transcript'] = transcript_data
            
            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            if transcript_data:
                speakers = set(t.get('speaker', '') for t in transcript_data if t.get('speaker'))
                result['statistics'] = {
                    'speakers_count': len(speakers),
                    'segments_count': len(transcript_data),
                    'total_characters': sum(len(t.get('text', '')) for t in transcript_data),
                    'speakers': list(speakers)
                }
        
        # å¯é€‰ï¼šåŒ…å«ä¼šè®®çºªè¦
        if include_summary and file_info.get('meeting_summary'):
            result['summary'] = file_info['meeting_summary']
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ–‡ä»¶è¯¦æƒ…å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f'è·å–æ–‡ä»¶è¯¦æƒ…å¤±è´¥: {str(e)}')


@router.patch("/files/{file_id}")
async def update_file(file_id: str, request: Request):
    """
    ğŸ”„ æ›´æ–°æ–‡ä»¶ï¼ˆRESTfulé£æ ¼ï¼Œæ–¹æ¡ˆ2ä¼˜åŒ–ï¼‰
    
    è·¯å¾„å‚æ•°ï¼š
    - file_id: æ–‡ä»¶ID
    
    è¯·æ±‚ä½“ï¼š
    - action: æ“ä½œç±»å‹ (retranscribe/generate_summary)
    - language: è¯­è¨€ï¼ˆé‡æ–°è½¬å†™æ—¶ï¼‰
    - hotword: çƒ­è¯ï¼ˆé‡æ–°è½¬å†™æ—¶ï¼‰
    
    è¿”å›ï¼šæ›´æ–°åçš„æ–‡ä»¶ä¿¡æ¯
    """
    try:
        body = await request.json()
        action = body.get('action')
        
        file_info = next((f for f in uploaded_files_manager.get_all_files() if f['id'] == file_id), None)
        
        if not file_info:
            raise HTTPException(status_code=404, detail='æ–‡ä»¶ä¸å­˜åœ¨')
        
        if action == 'retranscribe':
            # é‡æ–°è½¬å†™
            if file_info['status'] == 'processing':
                raise HTTPException(status_code=400, detail='æ–‡ä»¶æ­£åœ¨å¤„ç†ä¸­')
            
            language = body.get('language', file_info.get('language', 'zh'))
            hotword = body.get('hotword', '')
            
            # é‡ç½®çŠ¶æ€
            file_info['status'] = 'processing'
            file_info['progress'] = 0
            file_info['language'] = language
            
            # æäº¤è½¬å†™ä»»åŠ¡
            def retranscribe_task():
                try:
                    def update_progress(step, progress, message="", transcript_entry=None):
                        file_info['progress'] = progress
                        send_ws_message_sync(file_id, 'processing', progress, message)
                    
                    # âœ… æ‰§è¡Œè½¬å†™ï¼ˆä¸å†éœ€è¦å…¨å±€é”ï¼‰
                    pipeline_service.set_callback(update_progress)
                    transcript, _, _ = pipeline_service.execute_transcription(
                        file_info['filepath'],
                        hotword=hotword,
                        language=language,
                        instance_id=file_id
                    )
                    
                    if transcript:
                        file_info['transcript_data'] = transcript
                        # âœ… ä¿®å¤ï¼šä¼ å…¥ file_id ç¡®ä¿æ¯ä¸ªæ–‡ä»¶ç”Ÿæˆå”¯ä¸€çš„è½¬å†™æ–‡æ¡£æ–‡ä»¶å
                        filename, filepath = save_transcript_to_word(
                            transcript, language=language,
                            audio_filename=file_info['original_name'],
                            file_id=file_id
                        )
                        if filename:
                            file_info['transcript_file'] = filepath
                        
                        file_info['status'] = 'completed'
                        file_info['progress'] = 100
                        file_info['complete_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        save_history_to_file()
                        send_ws_message_sync(file_id, 'completed', 100, 'é‡æ–°è½¬å†™å®Œæˆ')
                    else:
                        file_info['status'] = 'error'
                        file_info['error_message'] = 'é‡æ–°è½¬å†™å¤±è´¥'
                        send_ws_message_sync(file_id, 'error', 0, 'é‡æ–°è½¬å†™å¤±è´¥')
                        
                except Exception as e:
                    logger.error(f"é‡æ–°è½¬å†™å¤±è´¥: {e}")
                    file_info['status'] = 'error'
                    file_info['error_message'] = str(e)
                    send_ws_message_sync(file_id, 'error', 0, f"é‡æ–°è½¬å†™å¤±è´¥: {str(e)}")
            
            TRANSCRIPTION_THREAD_POOL.submit(retranscribe_task)
            
            return {
                'success': True,
                'message': 'å·²å¼€å§‹é‡æ–°è½¬å†™',
                'file_id': file_id,
                'status': 'processing'
            }
        
        elif action == 'generate_summary':
            # ç”Ÿæˆä¼šè®®çºªè¦
            if file_info['status'] != 'completed':
                raise HTTPException(status_code=400, detail='æ–‡ä»¶è½¬å†™æœªå®Œæˆ')
            
            transcript_data = file_info.get('transcript_data', [])
            if not transcript_data:
                raise HTTPException(status_code=400, detail='æ²¡æœ‰è½¬å†™ç»“æœ')
            
            summary = generate_meeting_summary(transcript_data)
            if summary:
                file_info['meeting_summary'] = summary
                save_history_to_file()
                return {
                    'success': True,
                    'message': 'ä¼šè®®çºªè¦ç”ŸæˆæˆåŠŸ',
                    'summary': summary
                }
            else:
                raise HTTPException(status_code=500, detail='ç”Ÿæˆä¼šè®®çºªè¦å¤±è´¥')
        
        else:
            raise HTTPException(status_code=400, detail=f'ä¸æ”¯æŒçš„æ“ä½œ: {action}')
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æ›´æ–°æ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f'æ›´æ–°æ–‡ä»¶å¤±è´¥: {str(e)}')


# ==================== åŸæœ‰æ¥å£ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰ ====================

@router.post("/upload")
async def upload_audio(audio_file: UploadFile = File(...)):
    """ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"""
    if not audio_file.filename:
        return JSONResponse({'success': False, 'message': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'})
    
    if not allowed_file(audio_file.filename):
        return JSONResponse({'success': False, 'message': 'ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼'})
    
    try:
        filename = secure_filename(audio_file.filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        name, ext = os.path.splitext(filename)
        safe_filename = f"{name}_{timestamp}{ext}"
        
        contents = await audio_file.read()
        file_size = len(contents)
        filepath = audio_storage.save_uploaded_file(contents, safe_filename)
        
        file_id = str(uuid.uuid4())
        
        file_info = {
            'id': file_id,
            'filename': safe_filename,
            'original_name': audio_file.filename,
            'filepath': filepath,
            'size': file_size,
            'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'status': 'uploaded',
            'progress': 0,
            'error_message': ''
        }
        
        uploaded_files_manager.add_file(file_info)
        logger.info(f"æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {audio_file.filename}, ID: {file_id}")
        
        return {
            'success': True,
            'message': 'æ–‡ä»¶ä¸Šä¼ æˆåŠŸ',
            'file': file_info
        }
    except Exception as e:
        logger.error(f"æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {e}")
        return JSONResponse({'success': False, 'message': f'æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}'})


@router.post("/transcribe")
async def transcribe(request: Request):
    """å¼€å§‹è½¬å†™ï¼ˆæ”¯æŒæ‰¹é‡å’Œå¹¶å‘å¤„ç†ï¼›æ”¯æŒç­‰å¾…å®Œæˆå†è¿”å›ï¼‰"""
    global TRANSCRIPTION_THREAD_POOL
    
    try:
        body = await request.json()
        
        # âœ… å…¼å®¹æ¨¡å¼ï¼šåŒæ—¶æ”¯æŒ file_id (å•ä¸ª) å’Œ file_ids (æ•°ç»„)
        file_ids = body.get('file_ids', [])
        file_id = body.get('file_id', '')
        
        # å¦‚æœæä¾›äº†å•ä¸ª file_idï¼Œè½¬æ¢ä¸ºæ•°ç»„
        if file_id and not file_ids:
            file_ids = [file_id]
        # å¦‚æœ file_ids æ˜¯å­—ç¬¦ä¸²ï¼ˆæŸäº›æƒ…å†µä¸‹ï¼‰ï¼Œä¹Ÿè½¬æ¢ä¸ºæ•°ç»„
        elif isinstance(file_ids, str):
            file_ids = [file_ids]
        
        language = body.get('language', 'zh')
        hotword = body.get('hotword', '')
        # æ–°å¢ï¼šæ˜¯å¦ç­‰å¾…å®Œæˆä»¥åŠè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        wait_until_complete = body.get('wait', True)
        timeout_seconds = int(body.get('timeout', 3600))  # é»˜è®¤æœ€å¤šç­‰å¾…1å°æ—¶
    except:
        return {'success': False, 'message': 'è¯·æ±‚å‚æ•°é”™è¯¯'}
    
    if not file_ids:
        return {'success': False, 'message': 'è¯·é€‰æ‹©è¦è½¬å†™çš„æ–‡ä»¶ï¼ˆfile_id æˆ– file_idsï¼‰'}
    
    # æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯å¤„ç†
    files_to_process = []
    for file_id in file_ids:
        file_info = next((f for f in uploaded_files_manager.get_all_files() if f['id'] == file_id), None)
        if file_info:
            if file_info['status'] == 'processing':
                return {'success': False, 'message': f'æ–‡ä»¶ {file_info["original_name"]} æ­£åœ¨å¤„ç†ä¸­'}
            files_to_process.append(file_info)
        else:
            return {'success': False, 'message': f'æ–‡ä»¶ID {file_id} ä¸å­˜åœ¨'}
    
    if not files_to_process:
        return {'success': False, 'message': 'æ²¡æœ‰å¯å¤„ç†çš„æ–‡ä»¶'}
    
    # ğŸ”§ æå‰æ›´æ–°æ‰€æœ‰æ–‡ä»¶çŠ¶æ€ä¸º processingï¼Œè¿™æ ·å‰ç«¯ç«‹å³å¯ä»¥çœ‹åˆ°çŠ¶æ€å˜åŒ–
    for file_info in files_to_process:
        file_info['status'] = 'processing'
        file_info['progress'] = 0
        file_info['language'] = language
        uploaded_files_manager.add_to_processing(file_info['id'])
        logger.info(f"æ–‡ä»¶ {file_info['original_name']} çŠ¶æ€å·²æ›´æ–°ä¸º processing")
        
        # ğŸ”” WebSocketæ¨é€ï¼šå¼€å§‹è½¬å†™
        send_ws_message_sync(
            file_info['id'], 
            'processing', 
            0, 
            f"å¼€å§‹è½¬å†™: {file_info['original_name']}"
        )
    
    # å®šä¹‰å•æ–‡ä»¶å¤„ç†å‡½æ•°
    def process_single_file(file_info):
        try:
            file_id = file_info['id']
            logger.info(f"[çº¿ç¨‹æ± ] å¼€å§‹å¤„ç†æ–‡ä»¶: {file_info['original_name']}, çº¿ç¨‹: {threading.current_thread().name}")
            
            # æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if file_info.get('_cancelled', False):
                logger.info(f"[çº¿ç¨‹æ± ] æ–‡ä»¶ {file_id} å·²è¢«å–æ¶ˆï¼Œè·³è¿‡å¤„ç†")
                file_info['status'] = 'uploaded'
                file_info['progress'] = 0
                return
            
            # åˆ›å»ºè¿›åº¦å›è°ƒ
            def update_file_progress(step, progress, message="", transcript_entry=None):
                # æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
                if file_info.get('_cancelled', False):
                    logger.info(f"[çº¿ç¨‹æ± ] æ£€æµ‹åˆ°æ–‡ä»¶ {file_id} å·²è¢«å–æ¶ˆï¼Œåœæ­¢å¤„ç†")
                    raise InterruptedError("è½¬å†™ä»»åŠ¡å·²è¢«å–æ¶ˆ")
                
                file_info['progress'] = progress
                # ğŸ”” WebSocketæ¨é€ï¼šè¿›åº¦æ›´æ–°
                send_ws_message_sync(
                    file_id,
                    'processing',
                    progress,
                    message or f"å¤„ç†ä¸­: {step}"
                )
            
            # âœ… ä¸å†éœ€è¦å…¨å±€é” - æ¨¡å‹æ± å·²ç»å¤„ç†å¹¶å‘
            # è®¾ç½®å›è°ƒ
            pipeline_service.set_callback(update_file_progress)
            
            # å†æ¬¡æ£€æŸ¥æ˜¯å¦å·²è¢«å–æ¶ˆ
            if file_info.get('_cancelled', False):
                logger.info(f"[çº¿ç¨‹æ± ] æ–‡ä»¶ {file_id} åœ¨å¼€å§‹è½¬å†™å‰å·²è¢«å–æ¶ˆ")
                file_info['status'] = 'uploaded'
                file_info['progress'] = 0
                return
            
            logger.info(f"[çº¿ç¨‹æ± ] å¼€å§‹è½¬å†™: {file_info['original_name']}")
            transcript, _, _ = pipeline_service.execute_transcription(
                file_info['filepath'],
                hotword=hotword,
                language=language,
                instance_id=file_id,
                cancellation_flag=lambda: file_info.get('_cancelled', False)  # ä¼ é€’å–æ¶ˆæ£€æŸ¥å‡½æ•°
            )
            
            # æ£€æŸ¥æ˜¯å¦åœ¨è½¬å†™è¿‡ç¨‹ä¸­è¢«å–æ¶ˆ
            if file_info.get('_cancelled', False):
                logger.info(f"[çº¿ç¨‹æ± ] æ–‡ä»¶ {file_id} åœ¨è½¬å†™è¿‡ç¨‹ä¸­è¢«å–æ¶ˆ")
                file_info['status'] = 'uploaded'
                file_info['progress'] = 0
                file_info['error_message'] = 'è½¬å†™å·²åœæ­¢'
                send_ws_message_sync(
                    file_id,
                    'uploaded',
                    0,
                    'è½¬å†™å·²åœæ­¢'
                )
                return
            
            logger.info(f"[çº¿ç¨‹æ± ] è½¬å†™å®Œæˆ: {file_info['original_name']}")
            
            # ä¿å­˜è½¬å†™ç»“æœ
            if transcript:
                file_info['transcript_data'] = transcript
                logger.info(f"[çº¿ç¨‹æ± ] å·²ä¿å­˜ {len(transcript)} æ¡è½¬å†™è®°å½•")
                
                # è‡ªåŠ¨ç”ŸæˆWordæ–‡æ¡£
                # âœ… ä¿®å¤ï¼šä¼ å…¥ file_id ç¡®ä¿æ¯ä¸ªæ–‡ä»¶ç”Ÿæˆå”¯ä¸€çš„è½¬å†™æ–‡æ¡£æ–‡ä»¶å
                filename, filepath = save_transcript_to_word(
                    transcript,
                    language=language,
                    audio_filename=file_info['original_name'],
                    file_id=file_id
                )
                if filename:
                    file_info['transcript_file'] = filepath
                    logger.info(f"[çº¿ç¨‹æ± ] è½¬å†™æ–‡æ¡£å·²ä¿å­˜: {filename}")
                
                # æ›´æ–°çŠ¶æ€ä¸ºå®Œæˆ
                file_info['status'] = 'completed'
                file_info['progress'] = 100
                file_info['complete_time'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
                # æ·»åŠ åˆ°å·²å®Œæˆåˆ—è¡¨
                if file_info['id'] not in uploaded_files_manager.get_completed_files():
                    uploaded_files_manager.add_to_completed(file_info['id'])
                
                # ä¿å­˜å†å²è®°å½•
                save_history_to_file()
                
                # ğŸ”” WebSocketæ¨é€ï¼šè½¬å†™å®Œæˆ
                send_ws_message_sync(
                    file_info['id'],
                    'completed',
                    100,
                    f"è½¬å†™å®Œæˆ: {file_info['original_name']}"
                )
                
                logger.info(f"[çº¿ç¨‹æ± ] æ–‡ä»¶å¤„ç†å®Œæˆ: {file_info['original_name']}")
            else:
                file_info['status'] = 'error'
                file_info['error_message'] = 'è½¬å†™å¤±è´¥'
                
                # ğŸ”” WebSocketæ¨é€ï¼šè½¬å†™å¤±è´¥
                send_ws_message_sync(
                    file_info['id'],
                    'error',
                    0,
                    'è½¬å†™å¤±è´¥'
                )
                
        except InterruptedError as e:
            # å¤„ç†ä¸­æ–­å¼‚å¸¸
            file_id = file_info['id']
            logger.info(f"[çº¿ç¨‹æ± ] æ–‡ä»¶ {file_id} è½¬å†™è¢«ä¸­æ–­: {e}")
            file_info['status'] = 'uploaded'
            file_info['progress'] = 0
            file_info['error_message'] = 'è½¬å†™å·²åœæ­¢'
            
            # ğŸ”” WebSocketæ¨é€ï¼šè½¬å†™å·²åœæ­¢
            send_ws_message_sync(
                file_id,
                'uploaded',
                0,
                'è½¬å†™å·²åœæ­¢'
            )
        except Exception as e:
            file_id = file_info['id']
            logger.error(f"[çº¿ç¨‹æ± ] å¤„ç†æ–‡ä»¶å¤±è´¥ {file_info['original_name']}: {e}")
            
            # å¦‚æœæ˜¯å› ä¸ºå–æ¶ˆå¯¼è‡´çš„å¼‚å¸¸ï¼Œä¸æ ‡è®°ä¸ºé”™è¯¯
            if file_info.get('_cancelled', False):
                file_info['status'] = 'uploaded'
                file_info['progress'] = 0
                file_info['error_message'] = 'è½¬å†™å·²åœæ­¢'
                send_ws_message_sync(
                    file_id,
                    'uploaded',
                    0,
                    'è½¬å†™å·²åœæ­¢'
                )
            else:
                file_info['status'] = 'error'
                file_info['error_message'] = str(e)
                
                # ğŸ”” WebSocketæ¨é€ï¼šå¼‚å¸¸é”™è¯¯
                send_ws_message_sync(
                    file_id,
                    'error',
                    0,
                    f"å¤„ç†å¤±è´¥: {str(e)}"
                )
            
            import traceback
            traceback.print_exc()
        finally:
            file_id = file_info['id']
            # ä»å¤„ç†åˆ—è¡¨ä¸­ç§»é™¤
            if file_id in uploaded_files_manager.get_processing_files():
                uploaded_files_manager.remove_from_processing(file_id)
            
            # ä»ä»»åŠ¡å­—å…¸ä¸­ç§»é™¤
            with transcription_tasks_lock:
                if file_id in transcription_tasks:
                    del transcription_tasks[file_id]
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼Œå¹¶ä¿ç•™ future ä»¥ä¾¿å¯é€‰ç­‰å¾…
    futures = []
    for file_info in files_to_process:
        file_id = file_info['id']
        # åˆå§‹åŒ–å–æ¶ˆæ ‡å¿—
        file_info['_cancelled'] = False
        
        future = TRANSCRIPTION_THREAD_POOL.submit(process_single_file, file_info)
        futures.append((future, file_info))
        
        # å°†Futureå­˜å‚¨åˆ°ä»»åŠ¡å­—å…¸ä¸­ï¼Œç”¨äºå–æ¶ˆä»»åŠ¡
        with transcription_tasks_lock:
            transcription_tasks[file_id] = future
    
    logger.info(f"å·²æäº¤ {len(files_to_process)} ä¸ªæ–‡ä»¶åˆ°çº¿ç¨‹æ± å¤„ç†")
    
    # å¦‚æœéœ€è¦é˜»å¡ç­‰å¾…è‡³å®Œæˆï¼Œåˆ™è½®è¯¢ç­‰å¾…ç›´åˆ°å®Œæˆæˆ–è¶…æ—¶
    if wait_until_complete:
        import time as _time
        deadline = _time.time() + timeout_seconds
        pending_ids = set(fi['id'] for _, fi in futures)
        failed_ids = set()
        completed_ids = set()
        
        # è½®è¯¢çŠ¶æ€ç›´åˆ°å…¨éƒ¨å®Œæˆæˆ–è¶…æ—¶
        while _time.time() < deadline and pending_ids:
            finished_now = []
            for _, fi in futures:
                fid = fi['id']
                if fid not in pending_ids:
                    continue
                status = fi.get('status')
                if status in ('completed', 'error'):
                    finished_now.append(fid)
                    if status == 'completed':
                        completed_ids.add(fid)
                    else:
                        failed_ids.add(fid)
            for fid in finished_now:
                pending_ids.discard(fid)
            if pending_ids:
                _time.sleep(0.5)
        
        if pending_ids:
            # æœ‰æœªå®Œæˆä»»åŠ¡ï¼ˆè¶…æ—¶ï¼‰
            return {
                'success': False,
                'message': 'éƒ¨åˆ†ä»»åŠ¡æœªåœ¨è¶…æ—¶æ—¶é—´å†…å®Œæˆ',
                'completed_file_ids': sorted(list(completed_ids)),
                'failed_file_ids': sorted(list(failed_ids)),
                'pending_file_ids': sorted(list(pending_ids))
            }
        else:
            # å…¨éƒ¨å®Œæˆ
            return {
                'success': True,
                'message': f'è½¬å†™å®Œæˆ {len(completed_ids)} ä¸ªæ–‡ä»¶',
                'file_ids': sorted(list(completed_ids))
            }
    
    # éé˜»å¡å…¼å®¹æ¨¡å¼ï¼šç«‹å³è¿”å›â€œå·²å¼€å§‹è½¬å†™â€
    return {
        'success': True,
        'message': f'å·²å¼€å§‹è½¬å†™ {len(files_to_process)} ä¸ªæ–‡ä»¶',
        'file_ids': [f['id'] for f in files_to_process],
        'count': len(files_to_process)
    }


@router.post("/stop/{file_id}")
async def stop_transcription(file_id: str):
    """
    â¹ï¸ åœæ­¢è½¬å†™ï¼ˆå‘åå…¼å®¹æ¥å£ï¼‰
    
    å®ç°çœŸæ­£çš„ä»»åŠ¡ä¸­æ–­ï¼šå–æ¶ˆFutureå¹¶è®¾ç½®ä¸­æ–­æ ‡å¿—
    """
    file_info = next((f for f in uploaded_files_manager.get_all_files() if f['id'] == file_id), None)
    
    if not file_info:
        return {'success': False, 'message': 'æ–‡ä»¶ä¸å­˜åœ¨'}
    
    if file_info['status'] != 'processing':
        return {'success': False, 'message': 'æ–‡ä»¶æœªåœ¨è½¬å†™ä¸­'}
    
    # è®¾ç½®ä¸­æ–­æ ‡å¿—
    file_info['_cancelled'] = True
    logger.info(f"ğŸ›‘ è®¾ç½®æ–‡ä»¶ {file_id} çš„ä¸­æ–­æ ‡å¿—")
    
    # å°è¯•å–æ¶ˆFutureä»»åŠ¡
    with transcription_tasks_lock:
        if file_id in transcription_tasks:
            future = transcription_tasks[file_id]
            cancelled = future.cancel()
            if cancelled:
                logger.info(f"âœ… æˆåŠŸå–æ¶ˆæ–‡ä»¶ {file_id} çš„Futureä»»åŠ¡")
            else:
                logger.warning(f"âš ï¸ æ–‡ä»¶ {file_id} çš„Futureä»»åŠ¡æ— æ³•å–æ¶ˆï¼ˆå¯èƒ½å·²å¼€å§‹æ‰§è¡Œï¼‰")
            # ä»ä»»åŠ¡å­—å…¸ä¸­ç§»é™¤
            del transcription_tasks[file_id]
    
    # æ›´æ–°æ–‡ä»¶çŠ¶æ€
    file_info['status'] = 'uploaded'
    file_info['progress'] = 0
    file_info['error_message'] = 'è½¬å†™å·²åœæ­¢'
    
    if file_id in uploaded_files_manager.get_processing_files():
        uploaded_files_manager.remove_from_processing(file_id)
    
    # ğŸ”” WebSocketæ¨é€ï¼šè½¬å†™å·²åœæ­¢
    send_ws_message_sync(
        file_id,
        'uploaded',
        0,
        'è½¬å†™å·²åœæ­¢'
    )
    
    logger.info(f"ğŸ›‘ å·²åœæ­¢æ–‡ä»¶ {file_id} çš„è½¬å†™ä»»åŠ¡")
    return {'success': True, 'message': 'å·²åœæ­¢è½¬å†™'}


@router.get("/status/{file_id}")
async def get_status(file_id: str):
    """
    ğŸ“Š è·å–è½¬å†™çŠ¶æ€ï¼ˆå‘åå…¼å®¹æ¥å£ï¼‰
    
    æ¨èä½¿ç”¨æ–°æ¥å£: GET /api/voice/files/{file_id}
    """
    for f in uploaded_files_manager.get_all_files():
        if f['id'] == file_id:
            return {
                'success': True,
                'status': f['status'],
                'progress': f['progress'],
                'error_message': f.get('error_message', '')
            }
    
    return {'success': False, 'message': 'æ–‡ä»¶ä¸å­˜åœ¨'}


@router.get("/result/{file_id}")
async def get_result(file_id: str):
    """
    ğŸ“„ è·å–è½¬å†™ç»“æœï¼ˆå‘åå…¼å®¹æ¥å£ï¼‰
    
    æ¨èä½¿ç”¨æ–°æ¥å£: GET /api/voice/files/{file_id}?include_transcript=true&include_summary=true
    """
    for f in uploaded_files_manager.get_all_files():
        if f['id'] == file_id:
            if f['status'] != 'completed':
                return {'success': False, 'message': 'æ–‡ä»¶è½¬å†™æœªå®Œæˆ'}
            
            return {
                'success': True,
                'file_info': {
                    'id': f['id'],
                    'original_name': f['original_name'],
                    'upload_time': f['upload_time']
                },
                'transcript': f.get('transcript_data', []),
                'summary': f.get('meeting_summary')
            }
    
    return {'success': False, 'message': 'æ–‡ä»¶ä¸å­˜åœ¨'}


@router.get("/history")
async def list_history():
    """
    ğŸ“œ è·å–å†å²è®°å½•ï¼ˆå‘åå…¼å®¹æ¥å£ï¼‰
    
    æ¨èä½¿ç”¨æ–°æ¥å£: GET /api/voice/files?status=completed&include_history=true
    """
    # ä»æ–‡ä»¶åŠ è½½å†å²è®°å½•
    load_history_from_file()
    
    history_records = []
    for f in uploaded_files_manager.get_all_files():
        if f['status'] == 'completed':
            transcript_data = f.get('transcript_data', [])
            speakers = set(t.get('speaker', '') for t in transcript_data if t.get('speaker'))
            
            details = f"{len(speakers)}ä½å‘è¨€äºº, {len(transcript_data)}æ®µå¯¹è¯"
            
            history_records.append({
                'file_id': f['id'],
                'filename': f['original_name'],
                'transcribe_time': f.get('complete_time', f.get('upload_time', '-')),
                'status': 'completed',
                'details': details
            })
    
    history_records.sort(key=lambda x: x['transcribe_time'], reverse=True)
    
    logger.info(f"è¿”å› {len(history_records)} æ¡å†å²è®°å½•")
    
    return {
        'success': True,
        'records': history_records,
        'total': len(history_records)
    }


@router.delete("/files/{file_id}")
async def delete_file(file_id: str):
    """
    ğŸ—‘ï¸ åˆ é™¤æ–‡ä»¶ï¼ˆRESTfulæ ‡å‡†æ¥å£ï¼‰
    
    åˆ é™¤éŸ³é¢‘æ–‡ä»¶ã€è½¬å†™ç»“æœå’Œç›¸å…³æ–‡æ¡£
    
    ç‰¹æ®Šæ“ä½œï¼š
    - file_id = "_clear_dify": æ¸…ç©ºdifyç”Ÿæˆçš„.zipæ–‡ä»¶å’Œå¯¹åº”ä¸Šä¼ çš„éŸ³é¢‘
    - file_id = "_clear_all": æ¸…ç©ºæ‰€æœ‰å†å²è®°å½•ï¼ŒåŒ…æ‹¬æ‰€æœ‰è½¬å†™æ–‡ä»¶ä»¥åŠæ‰€æœ‰éŸ³é¢‘
    """
    # ç‰¹æ®Šæ“ä½œï¼šæ¸…ç©ºdifyç”Ÿæˆæ–‡ä»¶
    if file_id == "_clear_dify":
        try:
            deleted_count = 0
            deleted_zip_count = 0
            deleted_audio_count = 0
            deleted_transcript_count = 0
            
            # æ”¶é›†éœ€è¦åˆ é™¤çš„æ–‡ä»¶IDé›†åˆ
            files_to_delete = set()
            transcript_files_to_delete = set()
            
            # è·å–output_dirç›®å½•ä¸‹çš„æ‰€æœ‰transcripts_å¼€å¤´çš„.zipæ–‡ä»¶ï¼ˆä¸€ç«™å¼è½¬å†™æ¥å£ç”Ÿæˆçš„ï¼‰
            output_dir = FILE_CONFIG['output_dir']
            if os.path.exists(output_dir):
                for filename in os.listdir(output_dir):
                    # åªå¤„ç†transcripts_å¼€å¤´çš„.zipæ–‡ä»¶ï¼ˆä¸€ç«™å¼è½¬å†™æ¥å£ç”Ÿæˆçš„ï¼‰
                    if filename.startswith('transcripts_') and filename.endswith('.zip'):
                        zip_path = os.path.join(output_dir, filename)
                        try:
                            # è¯»å–ZIPæ–‡ä»¶å†…å®¹ï¼Œæ‰¾åˆ°å¯¹åº”çš„è½¬å†™æ–‡æ¡£
                            with zipfile.ZipFile(zip_path, 'r') as zipf:
                                zip_file_list = zipf.namelist()
                                logger.info(f"ZIPæ–‡ä»¶ {filename} åŒ…å« {len(zip_file_list)} ä¸ªæ–‡ä»¶")
                                
                                # æå–ZIPæ–‡ä»¶ä¸­çš„è½¬å†™æ–‡æ¡£æ–‡ä»¶å
                                for zip_entry in zip_file_list:
                                    if zip_entry.endswith('.docx'):
                                        # è½¬å†™æ–‡æ¡£æ–‡ä»¶åæ ¼å¼ï¼štranscript_YYYYMMDD_HHMMSS.docx
                                        transcript_filename = zip_entry
                                        transcript_files_to_delete.add(transcript_filename)
                                        logger.info(f"æ‰¾åˆ°è½¬å†™æ–‡æ¡£: {transcript_filename}")
                            
                            # åˆ é™¤ZIPæ–‡ä»¶
                            os.remove(zip_path)
                            deleted_zip_count += 1
                            logger.info(f"å·²åˆ é™¤difyç”Ÿæˆçš„ZIPæ–‡ä»¶: {filename}")
                        except Exception as e:
                            logger.error(f"å¤„ç†ZIPæ–‡ä»¶å¤±è´¥ {filename}: {e}")
            
            # é€šè¿‡è½¬å†™æ–‡æ¡£æ‰¾åˆ°å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶
            all_files = uploaded_files_manager.get_all_files()
            
            for file_info in all_files:
                # æ£€æŸ¥è½¬å†™æ–‡æ¡£æ˜¯å¦åœ¨è¦åˆ é™¤çš„åˆ—è¡¨ä¸­
                transcript_file = file_info.get('transcript_file')
                if transcript_file:
                    transcript_basename = os.path.basename(transcript_file)
                    # æ£€æŸ¥è½¬å†™æ–‡æ¡£æ˜¯å¦åœ¨ZIPæ–‡ä»¶ä¸­
                    if transcript_basename in transcript_files_to_delete:
                        files_to_delete.add(file_info['id'])
                        logger.info(f"æ‰¾åˆ°å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶: {file_info.get('original_name', 'unknown')} (ID: {file_info['id']})")
            
            # åˆ é™¤æ‰¾åˆ°çš„æ–‡ä»¶
            for file_id_to_delete in files_to_delete:
                file_info = uploaded_files_manager.get_file(file_id_to_delete)
                if not file_info:
                    continue
                
                try:
                    # åˆ é™¤éŸ³é¢‘æ–‡ä»¶
                    if 'filepath' in file_info and os.path.exists(file_info['filepath']):
                        os.remove(file_info['filepath'])
                        deleted_audio_count += 1
                        logger.info(f"å·²åˆ é™¤éŸ³é¢‘æ–‡ä»¶: {file_info['filepath']}")
                    
                    # åˆ é™¤è½¬å†™æ–‡æ¡£
                    if 'transcript_file' in file_info and os.path.exists(file_info['transcript_file']):
                        os.remove(file_info['transcript_file'])
                        deleted_transcript_count += 1
                        logger.info(f"å·²åˆ é™¤è½¬å†™æ–‡æ¡£: {file_info['transcript_file']}")
                    
                    # åˆ é™¤ä¼šè®®çºªè¦æ–‡æ¡£
                    if 'meeting_summary_file' in file_info and os.path.exists(file_info['meeting_summary_file']):
                        os.remove(file_info['meeting_summary_file'])
                        logger.info(f"å·²åˆ é™¤ä¼šè®®çºªè¦æ–‡æ¡£: {file_info['meeting_summary_file']}")
                    
                    # ä»å†…å­˜ä¸­åˆ é™¤
                    uploaded_files_manager.remove_file(file_id_to_delete)
                    deleted_count += 1
                except Exception as e:
                    logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_info.get('original_name', 'unknown')}: {e}")
            
            # ä¿å­˜æ›´æ–°åçš„å†å²è®°å½•
            save_history_to_file()
            
            logger.info(f"æ¸…ç©ºdifyç”Ÿæˆæ–‡ä»¶å®Œæˆ: åˆ é™¤ {deleted_zip_count} ä¸ªZIPæ–‡ä»¶, {deleted_audio_count} ä¸ªéŸ³é¢‘æ–‡ä»¶, {deleted_transcript_count} ä¸ªè½¬å†™æ–‡æ¡£, {deleted_count} æ¡å†å²è®°å½•")
            
            return {
                'success': True, 
                'message': f'æ¸…ç©ºdifyç”Ÿæˆæ–‡ä»¶æˆåŠŸ',
                'deleted': {
                    'zip_files': deleted_zip_count,
                    'audio_files': deleted_audio_count,
                    'transcript_files': deleted_transcript_count,
                    'records': deleted_count
                }
            }
        except Exception as e:
            logger.error(f"æ¸…ç©ºdifyç”Ÿæˆæ–‡ä»¶å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise HTTPException(status_code=500, detail=f'æ¸…ç©ºdifyç”Ÿæˆæ–‡ä»¶å¤±è´¥: {str(e)}')
    
    # ç‰¹æ®Šæ“ä½œï¼šæ¸…ç©ºæ‰€æœ‰å†å²è®°å½•
    elif file_id == "_clear_all":
        try:
            deleted_count = 0
            deleted_audio_count = 0
            deleted_transcript_count = 0
            
            # è·å–æ‰€æœ‰æ–‡ä»¶
            all_files = uploaded_files_manager.get_all_files()
            
            for file_info in all_files:
                # è·³è¿‡æ­£åœ¨å¤„ç†ä¸­çš„æ–‡ä»¶
                if file_info['status'] == 'processing':
                    continue
                
                try:
                    # åˆ é™¤éŸ³é¢‘æ–‡ä»¶
                    if 'filepath' in file_info and os.path.exists(file_info['filepath']):
                        os.remove(file_info['filepath'])
                        deleted_audio_count += 1
                        logger.info(f"å·²åˆ é™¤éŸ³é¢‘æ–‡ä»¶: {file_info['filepath']}")
                    
                    # åˆ é™¤è½¬å†™æ–‡æ¡£
                    if 'transcript_file' in file_info and os.path.exists(file_info['transcript_file']):
                        os.remove(file_info['transcript_file'])
                        deleted_transcript_count += 1
                        logger.info(f"å·²åˆ é™¤è½¬å†™æ–‡æ¡£: {file_info['transcript_file']}")
                    
                    # åˆ é™¤ä¼šè®®çºªè¦æ–‡æ¡£
                    if 'meeting_summary_file' in file_info and os.path.exists(file_info['meeting_summary_file']):
                        os.remove(file_info['meeting_summary_file'])
                        logger.info(f"å·²åˆ é™¤ä¼šè®®çºªè¦æ–‡æ¡£: {file_info['meeting_summary_file']}")
                    
                    # ä»å†…å­˜ä¸­åˆ é™¤
                    uploaded_files_manager.remove_file(file_info['id'])
                    deleted_count += 1
                except Exception as e:
                    logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥ {file_info.get('original_name', 'unknown')}: {e}")
            
            # æ¸…ç©ºoutput_dirç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆåŒ…æ‹¬.zipå’Œ.docxï¼‰
            output_dir = FILE_CONFIG['output_dir']
            if os.path.exists(output_dir):
                for filename in os.listdir(output_dir):
                    # è·³è¿‡history_records.jsonæ–‡ä»¶
                    if filename == 'history_records.json':
                        continue
                    file_path = os.path.join(output_dir, filename)
                    try:
                        if os.path.isfile(file_path):
                            os.remove(file_path)
                            logger.info(f"å·²åˆ é™¤è¾“å‡ºæ–‡ä»¶: {filename}")
                    except Exception as e:
                        logger.error(f"åˆ é™¤è¾“å‡ºæ–‡ä»¶å¤±è´¥ {filename}: {e}")
            
            # æ¸…ç©ºå†å²è®°å½•æ–‡ä»¶ï¼ˆä¿ç•™æ–‡ä»¶ä½†æ¸…ç©ºå†…å®¹ï¼‰
            try:
                with open(HISTORY_FILE, 'w', encoding='utf-8') as f:
                    json.dump({'files': [], 'completed_files': []}, f, ensure_ascii=False, indent=2)
                logger.info("å·²æ¸…ç©ºå†å²è®°å½•æ–‡ä»¶")
            except Exception as e:
                logger.error(f"æ¸…ç©ºå†å²è®°å½•æ–‡ä»¶å¤±è´¥: {e}")
            
            logger.info(f"æ¸…ç©ºæ‰€æœ‰å†å²è®°å½•å®Œæˆ: åˆ é™¤ {deleted_audio_count} ä¸ªéŸ³é¢‘æ–‡ä»¶, {deleted_transcript_count} ä¸ªè½¬å†™æ–‡æ¡£, {deleted_count} æ¡å†å²è®°å½•")
            
            return {
                'success': True, 
                'message': f'æ¸…ç©ºæ‰€æœ‰å†å²è®°å½•æˆåŠŸ',
                'deleted': {
                    'audio_files': deleted_audio_count,
                    'transcript_files': deleted_transcript_count,
                    'records': deleted_count
                }
            }
        except Exception as e:
            logger.error(f"æ¸…ç©ºæ‰€æœ‰å†å²è®°å½•å¤±è´¥: {e}")
            raise HTTPException(status_code=500, detail=f'æ¸…ç©ºæ‰€æœ‰å†å²è®°å½•å¤±è´¥: {str(e)}')
    
    # æ­£å¸¸åˆ é™¤å•ä¸ªæ–‡ä»¶
    file_info = uploaded_files_manager.get_file(file_id)
    
    if not file_info:
        raise HTTPException(status_code=404, detail='æ–‡ä»¶ä¸å­˜åœ¨')
    
    # âœ… ä¿®å¤ï¼šå¦‚æœæ–‡ä»¶æ­£åœ¨å¤„ç†ä¸­ï¼Œä½†å·²è®¾ç½®å–æ¶ˆæ ‡å¿—ï¼ˆåœæ­¢è½¬å†™ï¼‰ï¼Œå…è®¸åˆ é™¤
    if file_info['status'] == 'processing' and not file_info.get('_cancelled', False):
        raise HTTPException(status_code=400, detail='æ–‡ä»¶æ­£åœ¨å¤„ç†ä¸­ï¼Œæ— æ³•åˆ é™¤')
    
    try:
        # åˆ é™¤éŸ³é¢‘æ–‡ä»¶
        if os.path.exists(file_info['filepath']):
            os.remove(file_info['filepath'])
            logger.info(f"å·²åˆ é™¤éŸ³é¢‘æ–‡ä»¶: {file_info['filepath']}")
        
        # åˆ é™¤è½¬å†™æ–‡æ¡£ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'transcript_file' in file_info and os.path.exists(file_info['transcript_file']):
            os.remove(file_info['transcript_file'])
            logger.info(f"å·²åˆ é™¤è½¬å†™æ–‡æ¡£: {file_info['transcript_file']}")
        
        # åˆ é™¤ä¼šè®®çºªè¦æ–‡æ¡£ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if 'meeting_summary_file' in file_info and os.path.exists(file_info['meeting_summary_file']):
            os.remove(file_info['meeting_summary_file'])
            logger.info(f"å·²åˆ é™¤ä¼šè®®çºªè¦æ–‡æ¡£: {file_info['meeting_summary_file']}")
        
        # ä»å†…å­˜ä¸­åˆ é™¤ï¼ˆä½¿ç”¨çº¿ç¨‹å®‰å…¨æ–¹æ³•ï¼‰
        uploaded_files_manager.remove_file(file_id)
        
        # ä¿å­˜æ›´æ–°åçš„å†å²è®°å½•åˆ°ç£ç›˜
        save_history_to_file()
        
        # ğŸ”” WebSocketæ¨é€ï¼šæ–‡ä»¶å·²åˆ é™¤
        send_ws_message_sync(
            file_id,
            'deleted',
            0,
            f"æ–‡ä»¶å·²åˆ é™¤: {file_info['original_name']}"
        )
        
        logger.info(f"æ–‡ä»¶åˆ é™¤æˆåŠŸ: {file_info['original_name']}, ID: {file_id}")
        
        return {'success': True, 'message': 'æ–‡ä»¶åˆ é™¤æˆåŠŸ'}
        
    except Exception as e:
        logger.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f'åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}')


@router.get("/audio/{file_id}")
async def get_audio(file_id: str, download: int = 0):
    """è·å–éŸ³é¢‘æ–‡ä»¶"""
    file_info = next((f for f in uploaded_files_manager.get_all_files() if f['id'] == file_id), None)
    
    if not file_info:
        raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    
    if not os.path.exists(file_info['filepath']):
        raise HTTPException(status_code=404, detail="éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
    
    if download == 1:
        return FileResponse(
            file_info['filepath'],
            media_type='application/octet-stream',
            filename=file_info['original_name']
        )
    else:
        return FileResponse(
            file_info['filepath'],
            media_type='audio/mpeg'
        )


@router.get("/download_transcript/{file_id}")
async def download_transcript(file_id: str):
    """ä¸‹è½½è½¬å†™ç»“æœ"""
    file_info = next((f for f in uploaded_files_manager.get_all_files() if f['id'] == file_id), None)
    
    if not file_info:
        raise HTTPException(status_code=404, detail='æ–‡ä»¶ä¸å­˜åœ¨')
    
    if file_info['status'] != 'completed':
        raise HTTPException(status_code=400, detail='æ–‡ä»¶è½¬å†™æœªå®Œæˆ')
    
    if 'transcript_file' in file_info and file_info['transcript_file']:
        filepath = file_info['transcript_file']
        if os.path.exists(filepath):
            return FileResponse(
                path=filepath,
                filename=os.path.basename(filepath),
                media_type='application/vnd.openxmlformats-officedocument.wordprocessingml.document'
            )
    
    transcript_data = file_info.get('transcript_data', [])
    if not transcript_data:
        raise HTTPException(status_code=400, detail='æ²¡æœ‰è½¬å†™ç»“æœ')
    
    # âœ… ä¿®å¤ï¼šä¼ å…¥ file_id ç¡®ä¿æ¯ä¸ªæ–‡ä»¶ç”Ÿæˆå”¯ä¸€çš„è½¬å†™æ–‡æ¡£æ–‡ä»¶å
    filename, filepath = save_transcript_to_word(
        transcript_data,
        language=file_info.get('language', 'zh'),
        audio_filename=file_info.get('original_name'),
        file_id=file_id
    )
    
    if filename and os.path.exists(filepath):
        file_info['transcript_file'] = filepath
        return FileResponse(
            path=filepath,
            filename=filename,
            media_type='application/vnd.openxmlformats-officedocument.wordprocessingml.document'
        )
    else:
        raise HTTPException(status_code=500, detail='ç”ŸæˆWordæ–‡æ¡£å¤±è´¥')


@router.post("/generate_summary/{file_id}")
async def generate_summary_legacy(file_id: str):
    """
    ğŸ“ ç”Ÿæˆä¼šè®®çºªè¦ï¼ˆå‘åå…¼å®¹æ¥å£ï¼‰
    
    æ¨èä½¿ç”¨æ–°æ¥å£: PATCH /api/voice/files/{file_id} with action=generate_summary
    """
    file_info = next((f for f in uploaded_files_manager.get_all_files() if f['id'] == file_id), None)
    
    if not file_info:
        return {'success': False, 'message': 'æ–‡ä»¶ä¸å­˜åœ¨'}
    
    if file_info['status'] != 'completed':
        return {'success': False, 'message': 'æ–‡ä»¶è½¬å†™æœªå®Œæˆ'}
    
    transcript_data = file_info.get('transcript_data', [])
    if not transcript_data:
        return {'success': False, 'message': 'æ²¡æœ‰è½¬å†™ç»“æœ'}
    
    summary = generate_meeting_summary(transcript_data)
    
    if summary:
        file_info['meeting_summary'] = summary
        save_history_to_file()
        return {'success': True, 'summary': summary}
    else:
        return {'success': False, 'message': 'ç”Ÿæˆä¼šè®®çºªè¦å¤±è´¥'}


@router.get("/download_summary/{file_id}")
async def download_summary(file_id: str):
    """ä¸‹è½½ä¼šè®®çºªè¦"""
    file_info = next((f for f in uploaded_files_manager.get_all_files() if f['id'] == file_id), None)
    
    if not file_info:
        raise HTTPException(status_code=404, detail='æ–‡ä»¶ä¸å­˜åœ¨')
    
    if not file_info.get('meeting_summary'):
        raise HTTPException(status_code=400, detail='è¯·å…ˆç”Ÿæˆä¼šè®®çºªè¦')
    
    transcript_data = file_info.get('transcript_data', [])
    summary = file_info['meeting_summary']
    
    filename, filepath = save_meeting_summary_to_word(transcript_data, summary)
    
    if filename and os.path.exists(filepath):
        return FileResponse(
            path=filepath,
            filename=filename,
            media_type='application/vnd.openxmlformats-officedocument.wordprocessingml.document'
        )
    else:
        raise HTTPException(status_code=500, detail='ä¿å­˜Wordæ–‡æ¡£å¤±è´¥')


@router.get("/languages")
async def get_languages():
    """è·å–æ”¯æŒçš„è¯­è¨€åˆ—è¡¨"""
    return {
        'success': True,
        'languages': [
            {'value': key, 'name': value['name'], 'description': value['description']}
            for key, value in LANGUAGE_CONFIG.items()
        ]
    }


@router.get("/transcript_files")
async def list_transcript_files():
    """åˆ—å‡ºæ‰€æœ‰è½¬å†™æ–‡ä»¶"""
    try:
        files = audio_storage.list_output_files('.docx')
        for f in files:
            stat = os.stat(f['filepath'])
            f['modified'] = datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
            f['type'] = 'Wordæ–‡æ¡£'
        
        files.sort(key=lambda x: x['modified'], reverse=True)
        return {'success': True, 'files': files}
    except Exception as e:
        return {'success': False, 'message': str(e)}


@router.get("/download_file/{filename}")
async def download_file(filename: str):
    """
    ğŸ“¥ ä¸‹è½½è¾“å‡ºæ–‡ä»¶ï¼ˆWordæ–‡æ¡£ã€ZIPå‹ç¼©åŒ…ç­‰ï¼‰
    
    è·¯å¾„å‚æ•°ï¼š
    - filename: æ–‡ä»¶åï¼ˆä¾‹å¦‚ï¼štranscripts_20251101_203654.zipï¼‰
    
    ç”¨é€”ï¼š
    - ä¸‹è½½ /transcribe_all æ¥å£ç”Ÿæˆçš„ ZIP å‹ç¼©åŒ…
    - ä¸‹è½½å•ç‹¬çš„ Word è½¬å†™æ–‡æ¡£
    
    è¿”å›ï¼šæ–‡ä»¶æµ
    """
    try:
        filepath = os.path.join(FILE_CONFIG['output_dir'], filename)
        if os.path.exists(filepath):
            # æ ¹æ®æ–‡ä»¶æ‰©å±•åç¡®å®š MIME ç±»å‹
            if filename.endswith('.zip'):
                media_type = 'application/zip'
            elif filename.endswith('.docx'):
                media_type = 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
            else:
                media_type = 'application/octet-stream'
            
            return FileResponse(
                filepath,
                media_type=media_type,
                filename=filename
            )
        else:
            raise HTTPException(status_code=404, detail="æ–‡ä»¶ä¸å­˜åœ¨")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.delete("/delete_file/{filename}")
async def delete_output_file(filename: str):
    """åˆ é™¤è¾“å‡ºæ–‡ä»¶"""
    try:
        filepath = os.path.join(FILE_CONFIG['output_dir'], filename)
        if os.path.exists(filepath):
            os.remove(filepath)
            return {'success': True, 'message': 'æ–‡ä»¶åˆ é™¤æˆåŠŸ'}
        else:
            return {'success': False, 'message': 'æ–‡ä»¶ä¸å­˜åœ¨'}
    except Exception as e:
        return {'success': False, 'message': f'åˆ é™¤å¤±è´¥: {str(e)}'}


@router.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """
    WebSocketç«¯ç‚¹ - å®æ—¶æ¨é€æ–‡ä»¶çŠ¶æ€æ›´æ–°
    
    å®¢æˆ·ç«¯å¯ä»¥é€šè¿‡æ­¤WebSocketè¿æ¥æ¥æ”¶ï¼š
    - æ–‡ä»¶ä¸Šä¼ çŠ¶æ€
    - è½¬å†™è¿›åº¦æ›´æ–°
    - è½¬å†™å®Œæˆé€šçŸ¥
    - é”™è¯¯æç¤º
    """
    await ws_manager.connect(websocket)
    
    try:
        # å‘é€è¿æ¥æˆåŠŸæ¶ˆæ¯
        await websocket.send_json({
            "type": "connected",
            "message": "WebSocketè¿æ¥å·²å»ºç«‹"
        })
        
        # ä¿æŒè¿æ¥å¹¶å¤„ç†å®¢æˆ·ç«¯æ¶ˆæ¯
        while True:
            data = await websocket.receive_text()
            # å¯ä»¥å¤„ç†å®¢æˆ·ç«¯å‘é€çš„æ¶ˆæ¯ï¼ˆå¦‚è®¢é˜…ç‰¹å®šæ–‡ä»¶ï¼‰
            try:
                message = json.loads(data)
                if message.get('type') == 'subscribe':
                    file_id = message.get('file_id')
                    if file_id:
                        ws_manager.subscribe_file(websocket, file_id)
                        await websocket.send_json({
                            "type": "subscribed",
                            "file_id": file_id,
                            "message": f"å·²è®¢é˜…æ–‡ä»¶ {file_id} çš„çŠ¶æ€æ›´æ–°"
                        })
            except json.JSONDecodeError:
                pass
            
    except WebSocketDisconnect:
        ws_manager.disconnect(websocket)
        logger.info("WebSocketå®¢æˆ·ç«¯æ–­å¼€è¿æ¥")
    except Exception as e:
        logger.error(f"WebSocketé”™è¯¯: {e}")
        ws_manager.disconnect(websocket)


# ==================== Dify ä¸“ç”¨é˜²å¡æ­»æ¥å£ ====================

@router.post("/dify_safe_transcribe")
async def dify_safe_transcribe(
    audio_file: UploadFile = File(...),
    language: str = Form("zh"),
    hotword: str = Form("")
):
    """
    ğŸ”§ Dify å®‰å…¨è½¬å†™æ¥å£ - é˜²å¡æ­»ç‰ˆæœ¬

    ç‰¹ç‚¹ï¼š
    1. åªå¤„ç†å•ä¸ªæ–‡ä»¶
    2. ç«‹å³è¿”å›å“åº”ï¼Œä¸ç­‰å¾…è½¬å†™å®Œæˆ
    3. åå°å¼‚æ­¥å¤„ç†ï¼Œç¡®ä¿å‰ç«¯ä¸ä¼šå¡æ­»
    4. è¿”å›ä»»åŠ¡IDä¾›åç»­æŸ¥è¯¢

    ä½¿ç”¨æµç¨‹ï¼š
    1. è°ƒç”¨æ­¤æ¥å£ä¸Šä¼ æ–‡ä»¶
    2. ç«‹å³è·å¾— task_id
    3. ä½¿ç”¨ /api/voice/files/{task_id} æŸ¥è¯¢çŠ¶æ€
    4. å®Œæˆåä½¿ç”¨ /api/voice/result/{task_id} è·å–ç»“æœ
    """
    try:
        # å¿«é€ŸéªŒè¯
        if not audio_file.filename:
            return JSONResponse({'success': False, 'message': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}, status_code=400)

        if not allowed_file(audio_file.filename):
            return JSONResponse({'success': False, 'message': f'æ–‡ä»¶ {audio_file.filename} æ ¼å¼ä¸æ”¯æŒ'}, status_code=400)

        logger.info(f"[Difyå®‰å…¨è½¬å†™] æ¥æ”¶æ–‡ä»¶: {audio_file.filename}")

        # ä¿å­˜æ–‡ä»¶
        try:
            filename = secure_filename(audio_file.filename)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            name, ext = os.path.splitext(filename)
            safe_filename = f"{name}_{timestamp}{ext}"

            contents = await audio_file.read()
            file_size = len(contents)
            filepath = audio_storage.save_uploaded_file(contents, safe_filename)
            task_id = str(uuid.uuid4())

            # åˆ›å»ºæ–‡ä»¶è®°å½•
            file_info = {
                'id': task_id,
                'filename': safe_filename,
                'original_name': audio_file.filename,
                'filepath': filepath,
                'size': file_size,
                'upload_time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                'status': 'uploaded',
                'progress': 0,
                'language': language,
                'hotword': hotword
            }

            uploaded_files_manager.add_file(file_info)
            logger.info(f"[Difyå®‰å…¨è½¬å†™] æ–‡ä»¶å·²ä¿å­˜: {audio_file.filename}, ID: {task_id}")

        except Exception as e:
            logger.error(f"[Difyå®‰å…¨è½¬å†™] ä¿å­˜æ–‡ä»¶å¤±è´¥: {e}")
            return JSONResponse({'success': False, 'message': f'æ–‡ä»¶ä¿å­˜å¤±è´¥: {str(e)}'}, status_code=500)

        # ğŸ¯ å…³é”®ä¿®å¤ï¼šç«‹å³è¿”å›ï¼Œä¸å¼€å§‹è½¬å†™
        # è®© Dify å‰ç«¯ç«‹å³æ”¶åˆ°å“åº”ï¼Œç„¶åä½¿ç”¨å•ç‹¬çš„æ¥å£å¼€å§‹è½¬å†™
        return {
            'success': True,
            'message': 'æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼Œå¯ä»¥å¼€å§‹è½¬å†™',
            'task_id': task_id,
            'filename': audio_file.filename,
            'size': file_size,
            'status': 'uploaded',
            'next_step': {
                'action': 'start_transcription',
                'api': '/api/voice/transcribe',
                'method': 'POST',
                'body': {
                    'file_id': task_id,
                    'language': language,
                    'hotword': hotword,
                    'wait': False  # å…³é”®ï¼šä¸ç­‰å¾…å®Œæˆ
                }
            },
            'status_query': f'/api/voice/files/{task_id}',
            'result_query': f'/api/voice/result/{task_id}',
            'note': 'å‰ç«¯ä¸ä¼šå¡æ­»ï¼Œæ–‡ä»¶å·²å‡†å¤‡å¥½è½¬å†™'
        }

    except Exception as e:
        logger.error(f"[Difyå®‰å…¨è½¬å†™] å¤„ç†å¤±è´¥: {e}")
        return JSONResponse({'success': False, 'message': f'å¤„ç†å¤±è´¥: {str(e)}'}, status_code=500)

