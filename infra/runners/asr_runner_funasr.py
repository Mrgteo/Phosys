"""
Infra - ASRæ‰§è¡Œå™¨ï¼ˆFunASR AutoModelç‰ˆæœ¬ï¼‰
ä½¿ç”¨FunASRçš„AutoModelå®ç°ASRå’Œè¯´è¯äººè¯†åˆ«ä¸€ä½“åŒ–
ä¸demo.pyä¿æŒä¸€è‡´
"""

import os
import logging
import torch
from typing import Optional, List, Dict

# ç¦ç”¨FunASRçš„è¡¨å•æ‰“å°
os.environ['FUNASR_CACHE_DIR'] = os.path.expanduser('~/.cache/modelscope')
import warnings
warnings.filterwarnings('ignore')

from funasr import AutoModel

from .model_pool import ModelPool

logger = logging.getLogger(__name__)


class FunASRModelWrapper:
    """FunASR AutoModelåŒ…è£…å™¨ï¼Œç”¨äºæ± åŒ–ç®¡ç†"""
    
    def __init__(self, model_config: dict):
        logger.info("æ­£åœ¨åˆ›å»ºFunASR AutoModelå®ä¾‹...")
        
        # æ£€æµ‹è®¾å¤‡å’Œç¡¬ä»¶èµ„æºï¼ˆä¸demo.pyä¸€è‡´ï¼‰
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        ngpu = 1 if self.device == "cuda" else 0
        
        # è·å–CPUæ ¸å¿ƒæ•°ï¼ˆé™åˆ¶æœ€å¤§å€¼ï¼Œé¿å…è¶…å¤§æœåŠ¡å™¨å¯¼è‡´å†…å­˜é—®é¢˜ï¼‰
        try:
            import psutil
            ncpu = psutil.cpu_count()
        except:
            import multiprocessing
            ncpu = multiprocessing.cpu_count()
        
        # âš ï¸ é™åˆ¶CPUæ ¸å¿ƒæ•°ï¼Œé¿å…åœ¨å¤§å‹æœåŠ¡å™¨ä¸Šåˆ†é…è¿‡å¤šå†…å­˜
        # FunASRæ¯ä¸ªæ ¸å¿ƒä¼šåˆ†é…ä¸€å®šå†…å­˜ï¼Œ112æ ¸å¯èƒ½å¯¼è‡´OOM
        ncpu = min(ncpu, 16)  # æœ€å¤šä½¿ç”¨16ä¸ªæ ¸å¿ƒ
        
        logger.info(f"ä½¿ç”¨è®¾å¤‡: {self.device}, GPUæ•°: {ngpu}, CPUæ ¸å¿ƒæ•°: {ncpu}")
        
        # åˆ›å»ºAutoModelï¼ˆé›†æˆASRã€VADã€PUNCã€è¯´è¯äººè¯†åˆ«ï¼‰
        # å‚æ•°ä¸demo.pyå®Œå…¨ä¸€è‡´
        self.model = AutoModel(
            model=model_config['asr']['model_id'],
            model_revision=model_config['asr']['model_revision'],
            vad_model=model_config['vad']['model_id'],
            vad_model_revision=model_config['vad']['model_revision'],
            punc_model=model_config['punc']['model_id'],
            punc_model_revision=model_config['punc']['model_revision'],
            spk_model=model_config['diarization']['model_id'],  # è¯´è¯äººè¯†åˆ«æ¨¡å‹
            spk_model_revision=model_config['diarization']['revision'],
            ngpu=ngpu,  # GPUæ•°é‡
            ncpu=ncpu,  # CPUæ ¸å¿ƒæ•°
            device=self.device,
            disable_pbar=True,
            disable_log=True,  # ç¦ç”¨æ—¥å¿—ï¼Œé˜²æ­¢æ‰“å°è¡¨å•
            disable_update=True
        )
        
        logger.info("FunASR AutoModelå®ä¾‹åˆ›å»ºæˆåŠŸ")
    
    def transcribe_with_speaker(self, audio_input, hotword: str = '') -> Dict:
        """
        æ‰§è¡ŒASRå’Œè¯´è¯äººè¯†åˆ«ï¼ˆä¸€ä½“åŒ–ï¼‰
        
        Args:
            audio_input: éŸ³é¢‘è¾“å…¥ï¼ˆå­—èŠ‚æµæˆ–æ–‡ä»¶è·¯å¾„ï¼‰
            hotword: çƒ­è¯
            
        Returns:
            åŒ…å«æ–‡æœ¬å’Œè¯´è¯äººä¿¡æ¯çš„ç»“æœ
        """
        try:
            # å‡†å¤‡generateå‚æ•°
            generate_kwargs = {
                'input': audio_input,
                'use_itn': True,
                'batch_size_s': 60,
                'is_final': True,
                'sentence_timestamp': True
            }
            
            # åªæœ‰å½“hotwordéç©ºæ—¶æ‰ä¼ é€’ï¼ˆé¿å…ç©ºå­—ç¬¦ä¸²è¢«è§£æä¸º['<s>']ï¼‰
            if hotword and hotword.strip():
                generate_kwargs['hotword'] = hotword
            
            # è°ƒç”¨FunASRç”Ÿæˆ
            res = self.model.generate(**generate_kwargs)
            
            if not res or len(res) == 0:
                return None
            
            return res[0]  # è¿”å›ç¬¬ä¸€ä¸ªç»“æœ
            
        except Exception as e:
            logger.error(f"FunASRè½¬å†™å¤±è´¥: {e}")
            raise
    
    def cleanup(self):
        """æ¸…ç†æ¨¡å‹èµ„æº"""
        try:
            if hasattr(self, 'model'):
                del self.model
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
        except Exception as e:
            logger.error(f"æ¸…ç†FunASRæ¨¡å‹èµ„æºå¤±è´¥: {e}")


class ASRRunner:
    """ASRæ‰§è¡Œå™¨ - ä½¿ç”¨FunASR AutoModelï¼ˆæ”¯æŒæ¨¡å‹æ± ï¼‰"""
    
    def __init__(self, model_config: dict, use_pool: bool = True, pool_size: int = 3):
        """
        åˆå§‹åŒ–ASRè¿è¡Œå™¨ï¼ˆFunASRæ–¹å¼ï¼‰
        
        Args:
            model_config: æ¨¡å‹é…ç½®
            use_pool: æ˜¯å¦ä½¿ç”¨æ¨¡å‹æ± ï¼ˆç”Ÿäº§ç¯å¢ƒæ¨èå¼€å¯ï¼‰
            pool_size: æ¨¡å‹æ± å¤§å°
        """
        self.model_config = model_config
        self.use_pool = use_pool
        
        if use_pool:
            logger.info(f"ä½¿ç”¨FunASR AutoModel + æ¨¡å‹æ± æ¨¡å¼ï¼Œæ± å¤§å°: {pool_size}")
            # åˆ›å»ºæ¨¡å‹å·¥å‚å‡½æ•°
            def funasr_factory():
                return FunASRModelWrapper(model_config)
            
            # åˆ›å»ºæ¨¡å‹æ± 
            self.model_pool = ModelPool(
                model_factory=funasr_factory,
                initial_size=min(pool_size, 2),  # åˆå§‹åˆ›å»ºè¾ƒå°‘å®ä¾‹
                max_size=pool_size,
                min_size=1,
                max_idle_time=600,  # 10åˆ†é’Ÿ
                health_check_interval=300  # 5åˆ†é’Ÿï¼Œé™ä½æ—¥å¿—é¢‘ç‡
            )
            self.model = None
        else:
            logger.info("ä½¿ç”¨FunASR AutoModelå•ä¾‹æ¨¡å¼")
            self.model_pool = None
            self.model = FunASRModelWrapper(model_config)
    
    def transcribe_with_speaker(self, audio_input, hotword: str = '') -> Optional[List[Dict]]:
        """
        æ‰§è¡Œè¯­éŸ³è¯†åˆ«å’Œè¯´è¯äººè¯†åˆ«ï¼ˆFunASRä¸€ä½“åŒ–æ–¹å¼ï¼‰
        
        Args:
            audio_input: éŸ³é¢‘è¾“å…¥ï¼ˆå­—èŠ‚æµbytesæˆ–æ–‡ä»¶è·¯å¾„strï¼‰
            hotword: çƒ­è¯
            
        Returns:
            List[Dict]: è½¬å†™ç»“æœåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å«ï¼š
                - text: æ–‡æœ¬å†…å®¹
                - start: å¼€å§‹æ—¶é—´(æ¯«ç§’)
                - end: ç»“æŸæ—¶é—´(æ¯«ç§’)
                - spk: è¯´è¯äººID
        """
        try:
            input_type = "å­—èŠ‚æµ" if isinstance(audio_input, bytes) else "æ–‡ä»¶"
            logger.info(f"ğŸ™ï¸ å¼€å§‹FunASRä¸€ä½“åŒ–è½¬å†™ (è¾“å…¥ç±»å‹: {input_type})")
            if hotword and hotword.strip():
                logger.info(f"ğŸ“ ä½¿ç”¨çƒ­è¯: {hotword}")
            else:
                logger.info("ğŸ“ æ— çƒ­è¯")
            
            # æ ¹æ®æ¨¡å¼é€‰æ‹©æ‰§è¡Œæ–¹å¼
            if self.use_pool and self.model_pool:
                # ä½¿ç”¨æ¨¡å‹æ± 
                logger.info("â³ æ­£åœ¨ä»æ¨¡å‹æ± è·å–æ¨¡å‹å®ä¾‹...")
                with self.model_pool.acquire(timeout=60.0) as model:
                    logger.info("âœ… æ¨¡å‹è·å–æˆåŠŸï¼Œå¼€å§‹è½¬å½•...")
                    result = model.transcribe_with_speaker(audio_input, hotword)
            else:
                # ä½¿ç”¨å•ä¾‹æ¨¡å‹
                logger.info("ğŸ”„ ä½¿ç”¨å•ä¾‹æ¨¡å‹è¿›è¡Œè½¬å½•...")
                result = self.model.transcribe_with_speaker(audio_input, hotword)
            
            if not result:
                logger.warning("âš ï¸ FunASRè¿”å›ç©ºç»“æœ")
                return None
            
            # è§£æFunASRç»“æœæ ¼å¼
            transcript_list = []
            
            if 'sentence_info' in result:
                # æœ‰è¯´è¯äººä¿¡æ¯çš„ç»“æœ
                sentence_count = len(result['sentence_info'])
                
                # åˆ›å»ºè¯´è¯äººIDæ˜ å°„è¡¨ï¼ˆæŒ‰å‡ºç°é¡ºåºé‡æ–°ç¼–å·ï¼‰
                speaker_id_map = {}  # åŸå§‹spk -> è¿ç»­ç¼–å·
                next_speaker_number = 1
                
                for sentence in result['sentence_info']:
                    original_spk = sentence.get('spk', 0)
                    
                    # ç¬¬ä¸€æ¬¡é‡åˆ°è¿™ä¸ªè¯´è¯äººæ—¶ï¼Œåˆ†é…æ–°çš„è¿ç»­ç¼–å·
                    if original_spk not in speaker_id_map:
                        speaker_id_map[original_spk] = next_speaker_number
                        next_speaker_number += 1
                    
                    # ä½¿ç”¨æ˜ å°„åçš„è¿ç»­ç¼–å·
                    speaker_number = speaker_id_map[original_spk]
                    
                    transcript_list.append({
                        'text': sentence.get('text', ''),
                        'start_time': sentence.get('start', 0) / 1000.0,  # è½¬ä¸ºç§’
                        'end_time': sentence.get('end', 0) / 1000.0,
                        'speaker': f"å‘è¨€äºº{speaker_number}"  # ä½¿ç”¨è¿ç»­ç¼–å·
                    })
                
                logger.info(f"âœ… è¯†åˆ«å®Œæˆ: å…±{sentence_count}ä¸ªå¥å­, {len(speaker_id_map)}ä½è¯´è¯äºº")
            elif 'text' in result:
                # åªæœ‰æ–‡æœ¬ï¼Œæ²¡æœ‰è¯´è¯äººä¿¡æ¯
                logger.warning("âš ï¸ ç»“æœä¸­æ— è¯´è¯äººä¿¡æ¯ï¼Œä½œä¸ºå•äººå¤„ç†")
                transcript_list.append({
                    'text': result['text'],
                    'start_time': 0,
                    'end_time': 0,
                    'speaker': 'å‘è¨€äºº1'  # å•äººæ—¶é»˜è®¤ä¸ºå‘è¨€äºº1
                })
            
            return transcript_list
            
        except Exception as e:
            logger.error(f"âŒ FunASRè½¬å†™å¤±è´¥: {e}")
            raise
    
    def get_pool_stats(self) -> Optional[dict]:
        """è·å–æ¨¡å‹æ± ç»Ÿè®¡ä¿¡æ¯"""
        if self.use_pool and self.model_pool:
            return self.model_pool.get_stats()
        return None
    
    def shutdown(self):
        """å…³é—­è¿è¡Œå™¨ï¼Œæ¸…ç†èµ„æº"""
        if self.use_pool and self.model_pool:
            self.model_pool.shutdown()
        elif self.model:
            self.model.cleanup()

